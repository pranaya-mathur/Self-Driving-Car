{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHFnthirwlfn"
   },
   "outputs": [],
   "source": [
    "# Credits: https://github.com/SullyChen/Autopilot-TensorFlow\n",
    "# Research paper: End to End Learning for Self-Driving Cars by Nvidia. [https://arxiv.org/pdf/1604.07316.pdf]\n",
    "\n",
    "# NVidia dataset: 72 hrs of video => 72*60*60*30 = 7,776,000 images\n",
    "# Nvidia blog: https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "\n",
    "\n",
    "# Our Dataset: https://github.com/SullyChen/Autopilot-TensorFlow [https://drive.google.com/file/d/0B-KJCaaF7elleG1RbzVPZWV4Tlk/view]\n",
    "# Size: 25 minutes = 25*60*30 = 45,000 images ~ 2.3 GB\n",
    "\n",
    "\n",
    "# If you want to try on a slightly large dataset: 70 minutes of data ~ 223GB\n",
    "# Refer: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5\n",
    "# Format: Image, latitude, longitude, gear, brake, throttle, steering angles and speed\n",
    "\n",
    "\n",
    "\n",
    "# Additional Installations:\n",
    "# pip3 install h5py\n",
    "\n",
    "\n",
    "# AWS: https://aws.amazon.com/blogs/machine-learning/get-started-with-deep-learning-using-the-aws-deep-learning-ami/\n",
    "\n",
    "# Youtube:https://www.youtube.com/watch?v=qhUvQiKec2U\n",
    "# Further reading and extensions: https://medium.com/udacity/teaching-a-machine-to-steer-a-car-d73217f2492c\n",
    "# More data: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "7QC71ZfC1xsA",
    "outputId": "48d1f048-8133-4264-dba0-1d2d4d2faf3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mounting Google Drive\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgcc6iQobKHi"
   },
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.misc\n",
    "from scipy import pi\n",
    "from subprocess import call\n",
    "from datetime import datetime\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "boGdBfdf1lOe",
    "outputId": "abe0c781-7ba7-4e9f-d9aa-ee70f4a9fc40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyunpack\n",
      "  Downloading https://files.pythonhosted.org/packages/79/dc/44cd41fb99d184ae7c2eac439a52ca624d5ece62b0302c3437fcc4ce3b58/pyunpack-0.1.2.tar.gz\n",
      "Collecting easyprocess (from pyunpack)\n",
      "  Downloading https://files.pythonhosted.org/packages/45/3a/4eecc0c7995a13a64739bbedc0d3691fc574245b7e79cff81905aa0c2b38/EasyProcess-0.2.5.tar.gz\n",
      "Building wheels for collected packages: pyunpack, easyprocess\n",
      "  Building wheel for pyunpack (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/af/44/08/60613970881e542c0baad1f2dea5ed8e6716bc573f49197b7e\n",
      "  Building wheel for easyprocess (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/41/22/19/af15ef6264c58b625a82641ed7483ad05e258fbd8925505227\n",
      "Successfully built pyunpack easyprocess\n",
      "Installing collected packages: easyprocess, pyunpack\n",
      "Successfully installed easyprocess-0.2.5 pyunpack-0.1.2\n",
      "Collecting patool\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 3.8MB/s \n",
      "\u001b[?25hInstalling collected packages: patool\n",
      "Successfully installed patool-1.12\n"
     ]
    }
   ],
   "source": [
    "# Installing Required Libraries used for unpackin rar file\n",
    "!pip install pyunpack\n",
    "!pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBMsLiBF2Ubl"
   },
   "outputs": [],
   "source": [
    "# Creating a Directiory to store unpacked dataset\n",
    "\n",
    "os.mkdir(\"Driving Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_6v7LxLh2lLV"
   },
   "outputs": [],
   "source": [
    "from pyunpack import Archive\n",
    "Archive('drive/My Drive/Autopilot-TensorFlow-master.rar').extractall('Driving Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3uSVTyq2faN"
   },
   "outputs": [],
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "import scipy.misc\n",
    "import random\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(\"Driving Data/Autopilot-TensorFlow-master/Autopilot-TensorFlow-master/driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"Driving Data/Autopilot-TensorFlow-master/Autopilot-TensorFlow-master/driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "\n",
    "train_xs = xs[:int(len(xs) * 0.8)] # splitting data into 80:20 ratio, as per the task assigned\n",
    "train_ys = ys[:int(len(xs) * 0.8)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.2):]\n",
    "val_ys = ys[-int(len(xs) * 0.2):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)\n",
    "\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(val_xs[(val_batch_pointer + i) % num_val_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "syqlgL2T27M0",
    "outputId": "90b79946-2ee0-4400-adba-9b478526c0f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36324\n",
      "9081\n"
     ]
    }
   ],
   "source": [
    "print(num_train_images)\n",
    "print(num_val_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7mjY9-D3B9A"
   },
   "source": [
    "**Model 2: **\n",
    "\n",
    "1. Activation Used -- Linear\n",
    "2. Splitted Data into 80 : 20\n",
    "3. Optimizer Used Adam(learning rate = 1e-3)\n",
    "4. Dropout  0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "3Kt19HhJ3AmL",
    "outputId": "731edebf-a17b-4549-f3d4-436582062db6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-5-b91a6c6b022a>:56: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.multiply(tf.identity(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) #scale the atan output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 24058
    },
    "colab_type": "code",
    "id": "p8lJqmhH4n0l",
    "outputId": "48b5622b-c244-490f-eaaf-215e6dcc4ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch: 0, Step: 0, Loss: 6.35474\n",
      "Epoch: 0, Step: 10, Loss: 6.1559\n",
      "Epoch: 0, Step: 20, Loss: 5.63691\n",
      "Epoch: 0, Step: 30, Loss: 5.35489\n",
      "Epoch: 0, Step: 40, Loss: 5.12379\n",
      "Epoch: 0, Step: 50, Loss: 5.00859\n",
      "Epoch: 0, Step: 60, Loss: 5.01454\n",
      "Epoch: 0, Step: 70, Loss: 5.76963\n",
      "Epoch: 0, Step: 80, Loss: 6.3347\n",
      "Epoch: 0, Step: 90, Loss: 4.64813\n",
      "Epoch: 0, Step: 100, Loss: 4.29211\n",
      "Epoch: 0, Step: 110, Loss: 4.14591\n",
      "Epoch: 0, Step: 120, Loss: 4.07293\n",
      "Epoch: 0, Step: 130, Loss: 3.97827\n",
      "Epoch: 0, Step: 140, Loss: 3.90871\n",
      "Epoch: 0, Step: 150, Loss: 3.87411\n",
      "Epoch: 0, Step: 160, Loss: 3.76921\n",
      "Epoch: 0, Step: 170, Loss: 3.655\n",
      "Epoch: 0, Step: 180, Loss: 3.6519\n",
      "Epoch: 0, Step: 190, Loss: 3.87032\n",
      "Epoch: 0, Step: 200, Loss: 3.5008\n",
      "Epoch: 0, Step: 210, Loss: 3.52764\n",
      "Epoch: 0, Step: 220, Loss: 3.33275\n",
      "Epoch: 0, Step: 230, Loss: 3.27894\n",
      "Epoch: 0, Step: 240, Loss: 3.22791\n",
      "Epoch: 0, Step: 250, Loss: 3.17942\n",
      "Epoch: 0, Step: 260, Loss: 3.19471\n",
      "Epoch: 0, Step: 270, Loss: 7.85086\n",
      "Epoch: 0, Step: 280, Loss: 3.8921\n",
      "Epoch: 0, Step: 290, Loss: 3.00565\n",
      "Epoch: 0, Step: 300, Loss: 2.95793\n",
      "Epoch: 0, Step: 310, Loss: 2.91647\n",
      "Epoch: 0, Step: 320, Loss: 2.88159\n",
      "Epoch: 0, Step: 330, Loss: 2.84043\n",
      "Epoch: 0, Step: 340, Loss: 2.80632\n",
      "Epoch: 0, Step: 350, Loss: 2.76646\n",
      "Epoch: 0, Step: 360, Loss: 2.73276\n",
      "Epoch: 0, Step: 370, Loss: 2.6961\n",
      "Epoch: 0, Step: 380, Loss: 2.66995\n",
      "Epoch: 0, Step: 390, Loss: 2.63026\n",
      "Epoch: 0, Step: 400, Loss: 2.6164\n",
      "Epoch: 0, Step: 410, Loss: 2.56886\n",
      "Epoch: 0, Step: 420, Loss: 2.54374\n",
      "Epoch: 0, Step: 430, Loss: 2.49946\n",
      "Epoch: 0, Step: 440, Loss: 2.48102\n",
      "Epoch: 0, Step: 450, Loss: 2.44613\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 1, Step: 100, Loss: 2.43203\n",
      "Epoch: 1, Step: 110, Loss: 2.40972\n",
      "Epoch: 1, Step: 120, Loss: 2.37057\n",
      "Epoch: 1, Step: 130, Loss: 2.34158\n",
      "Epoch: 1, Step: 140, Loss: 2.3175\n",
      "Epoch: 1, Step: 150, Loss: 2.28888\n",
      "Epoch: 1, Step: 160, Loss: 2.26046\n",
      "Epoch: 1, Step: 170, Loss: 2.23288\n",
      "Epoch: 1, Step: 180, Loss: 2.20671\n",
      "Epoch: 1, Step: 190, Loss: 2.18163\n",
      "Epoch: 1, Step: 200, Loss: 2.15946\n",
      "Epoch: 1, Step: 210, Loss: 2.19031\n",
      "Epoch: 1, Step: 220, Loss: 2.4281\n",
      "Epoch: 1, Step: 230, Loss: 7.2623\n",
      "Epoch: 1, Step: 240, Loss: 2.07261\n",
      "Epoch: 1, Step: 250, Loss: 2.03953\n",
      "Epoch: 1, Step: 260, Loss: 2.05186\n",
      "Epoch: 1, Step: 270, Loss: 2.07242\n",
      "Epoch: 1, Step: 280, Loss: 2.05479\n",
      "Epoch: 1, Step: 290, Loss: 1.9562\n",
      "Epoch: 1, Step: 300, Loss: 2.04667\n",
      "Epoch: 1, Step: 310, Loss: 1.94803\n",
      "Epoch: 1, Step: 320, Loss: 1.89165\n",
      "Epoch: 1, Step: 330, Loss: 1.91454\n",
      "Epoch: 1, Step: 340, Loss: 1.86462\n",
      "Epoch: 1, Step: 350, Loss: 1.84205\n",
      "Epoch: 1, Step: 360, Loss: 1.86128\n",
      "Epoch: 1, Step: 370, Loss: 1.93306\n",
      "Epoch: 1, Step: 380, Loss: 1.82543\n",
      "Epoch: 1, Step: 390, Loss: 1.91836\n",
      "Epoch: 1, Step: 400, Loss: 1.80067\n",
      "Epoch: 1, Step: 410, Loss: 1.74335\n",
      "Epoch: 1, Step: 420, Loss: 1.71193\n",
      "Epoch: 1, Step: 430, Loss: 1.69106\n",
      "Epoch: 1, Step: 440, Loss: 1.67601\n",
      "Epoch: 1, Step: 450, Loss: 1.6568\n",
      "Epoch: 1, Step: 460, Loss: 1.64009\n",
      "Epoch: 1, Step: 470, Loss: 1.62444\n",
      "Epoch: 1, Step: 480, Loss: 1.62062\n",
      "Epoch: 1, Step: 490, Loss: 1.61386\n",
      "Epoch: 1, Step: 500, Loss: 1.60063\n",
      "Epoch: 1, Step: 510, Loss: 1.56512\n",
      "Epoch: 1, Step: 520, Loss: 1.56036\n",
      "Epoch: 1, Step: 530, Loss: 1.606\n",
      "Epoch: 1, Step: 540, Loss: 1.52983\n",
      "Epoch: 1, Step: 550, Loss: 1.89085\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 2, Step: 200, Loss: 2.10992\n",
      "Epoch: 2, Step: 210, Loss: 1.69962\n",
      "Epoch: 2, Step: 220, Loss: 1.51667\n",
      "Epoch: 2, Step: 230, Loss: 1.48593\n",
      "Epoch: 2, Step: 240, Loss: 1.44724\n",
      "Epoch: 2, Step: 250, Loss: 1.54319\n",
      "Epoch: 2, Step: 260, Loss: 2.44818\n",
      "Epoch: 2, Step: 270, Loss: 2.69382\n",
      "Epoch: 2, Step: 280, Loss: 1.44418\n",
      "Epoch: 2, Step: 290, Loss: 1.49865\n",
      "Epoch: 2, Step: 300, Loss: 1.35316\n",
      "Epoch: 2, Step: 310, Loss: 1.34115\n",
      "Epoch: 2, Step: 320, Loss: 1.33457\n",
      "Epoch: 2, Step: 330, Loss: 1.32455\n",
      "Epoch: 2, Step: 340, Loss: 1.33597\n",
      "Epoch: 2, Step: 350, Loss: 1.31129\n",
      "Epoch: 2, Step: 360, Loss: 1.27965\n",
      "Epoch: 2, Step: 370, Loss: 1.39381\n",
      "Epoch: 2, Step: 380, Loss: 1.67813\n",
      "Epoch: 2, Step: 390, Loss: 1.38693\n",
      "Epoch: 2, Step: 400, Loss: 1.32078\n",
      "Epoch: 2, Step: 410, Loss: 1.22217\n",
      "Epoch: 2, Step: 420, Loss: 1.21084\n",
      "Epoch: 2, Step: 430, Loss: 1.19748\n",
      "Epoch: 2, Step: 440, Loss: 1.18495\n",
      "Epoch: 2, Step: 450, Loss: 1.23949\n",
      "Epoch: 2, Step: 460, Loss: 6.65199\n",
      "Epoch: 2, Step: 470, Loss: 1.35662\n",
      "Epoch: 2, Step: 480, Loss: 1.14638\n",
      "Epoch: 2, Step: 490, Loss: 1.1296\n",
      "Epoch: 2, Step: 500, Loss: 1.12266\n",
      "Epoch: 2, Step: 510, Loss: 1.11514\n",
      "Epoch: 2, Step: 520, Loss: 1.10034\n",
      "Epoch: 2, Step: 530, Loss: 1.09204\n",
      "Epoch: 2, Step: 540, Loss: 1.07973\n",
      "Epoch: 2, Step: 550, Loss: 1.06875\n",
      "Epoch: 2, Step: 560, Loss: 1.05939\n",
      "Epoch: 2, Step: 570, Loss: 1.05097\n",
      "Epoch: 2, Step: 580, Loss: 1.0616\n",
      "Epoch: 2, Step: 590, Loss: 1.07321\n",
      "Epoch: 2, Step: 600, Loss: 1.04173\n",
      "Epoch: 2, Step: 610, Loss: 1.01057\n",
      "Epoch: 2, Step: 620, Loss: 1.00127\n",
      "Epoch: 2, Step: 630, Loss: 0.991927\n",
      "Epoch: 2, Step: 640, Loss: 0.983705\n",
      "Epoch: 2, Step: 650, Loss: 0.974091\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 3, Step: 300, Loss: 0.971078\n",
      "Epoch: 3, Step: 310, Loss: 0.962104\n",
      "Epoch: 3, Step: 320, Loss: 0.953495\n",
      "Epoch: 3, Step: 330, Loss: 0.944288\n",
      "Epoch: 3, Step: 340, Loss: 0.936595\n",
      "Epoch: 3, Step: 350, Loss: 0.927885\n",
      "Epoch: 3, Step: 360, Loss: 0.918836\n",
      "Epoch: 3, Step: 370, Loss: 0.910812\n",
      "Epoch: 3, Step: 380, Loss: 0.902875\n",
      "Epoch: 3, Step: 390, Loss: 0.897854\n",
      "Epoch: 3, Step: 400, Loss: 0.948002\n",
      "Epoch: 3, Step: 410, Loss: 2.42124\n",
      "Epoch: 3, Step: 420, Loss: 4.90484\n",
      "Epoch: 3, Step: 430, Loss: 0.874653\n",
      "Epoch: 3, Step: 440, Loss: 0.860313\n",
      "Epoch: 3, Step: 450, Loss: 0.881443\n",
      "Epoch: 3, Step: 460, Loss: 0.884937\n",
      "Epoch: 3, Step: 470, Loss: 0.877839\n",
      "Epoch: 3, Step: 480, Loss: 0.860117\n",
      "Epoch: 3, Step: 490, Loss: 0.982195\n",
      "Epoch: 3, Step: 500, Loss: 0.828266\n",
      "Epoch: 3, Step: 510, Loss: 0.818203\n",
      "Epoch: 3, Step: 520, Loss: 0.84176\n",
      "Epoch: 3, Step: 530, Loss: 0.79959\n",
      "Epoch: 3, Step: 540, Loss: 0.799094\n",
      "Epoch: 3, Step: 550, Loss: 0.842381\n",
      "Epoch: 3, Step: 560, Loss: 0.884924\n",
      "Epoch: 3, Step: 570, Loss: 0.83217\n",
      "Epoch: 3, Step: 580, Loss: 0.880801\n",
      "Epoch: 3, Step: 590, Loss: 0.773556\n",
      "Epoch: 3, Step: 600, Loss: 0.778644\n",
      "Epoch: 3, Step: 610, Loss: 0.757188\n",
      "Epoch: 3, Step: 620, Loss: 0.747454\n",
      "Epoch: 3, Step: 630, Loss: 0.741908\n",
      "Epoch: 3, Step: 640, Loss: 0.735886\n",
      "Epoch: 3, Step: 650, Loss: 0.732687\n",
      "Epoch: 3, Step: 660, Loss: 0.728273\n",
      "Epoch: 3, Step: 670, Loss: 0.737729\n",
      "Epoch: 3, Step: 680, Loss: 0.720564\n",
      "Epoch: 3, Step: 690, Loss: 0.721791\n",
      "Epoch: 3, Step: 700, Loss: 0.683149\n",
      "Epoch: 3, Step: 710, Loss: 0.714275\n",
      "Epoch: 3, Step: 720, Loss: 0.774626\n",
      "Epoch: 3, Step: 730, Loss: 0.675476\n",
      "Epoch: 3, Step: 740, Loss: 1.19029\n",
      "Epoch: 3, Step: 750, Loss: 1.2505\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 4, Step: 400, Loss: 0.844458\n",
      "Epoch: 4, Step: 410, Loss: 0.685371\n",
      "Epoch: 4, Step: 420, Loss: 0.662097\n",
      "Epoch: 4, Step: 430, Loss: 0.664611\n",
      "Epoch: 4, Step: 440, Loss: 0.851044\n",
      "Epoch: 4, Step: 450, Loss: 2.02321\n",
      "Epoch: 4, Step: 460, Loss: 1.72948\n",
      "Epoch: 4, Step: 470, Loss: 0.658053\n",
      "Epoch: 4, Step: 480, Loss: 0.667927\n",
      "Epoch: 4, Step: 490, Loss: 0.60517\n",
      "Epoch: 4, Step: 500, Loss: 0.605179\n",
      "Epoch: 4, Step: 510, Loss: 0.598618\n",
      "Epoch: 4, Step: 520, Loss: 0.616041\n",
      "Epoch: 4, Step: 530, Loss: 0.652094\n",
      "Epoch: 4, Step: 540, Loss: 0.58413\n",
      "Epoch: 4, Step: 550, Loss: 0.589868\n",
      "Epoch: 4, Step: 560, Loss: 0.688686\n",
      "Epoch: 4, Step: 570, Loss: 0.959621\n",
      "Epoch: 4, Step: 580, Loss: 0.783118\n",
      "Epoch: 4, Step: 590, Loss: 0.566596\n",
      "Epoch: 4, Step: 600, Loss: 0.556808\n",
      "Epoch: 4, Step: 610, Loss: 0.552674\n",
      "Epoch: 4, Step: 620, Loss: 0.548027\n",
      "Epoch: 4, Step: 630, Loss: 0.543418\n",
      "Epoch: 4, Step: 640, Loss: 1.0087\n",
      "Epoch: 4, Step: 650, Loss: 5.43834\n",
      "Epoch: 4, Step: 660, Loss: 0.561754\n",
      "Epoch: 4, Step: 670, Loss: 0.526286\n",
      "Epoch: 4, Step: 680, Loss: 0.518436\n",
      "Epoch: 4, Step: 690, Loss: 0.520082\n",
      "Epoch: 4, Step: 700, Loss: 0.510797\n",
      "Epoch: 4, Step: 710, Loss: 0.504419\n",
      "Epoch: 4, Step: 720, Loss: 0.493705\n",
      "Epoch: 4, Step: 730, Loss: 0.489855\n",
      "Epoch: 4, Step: 740, Loss: 0.485564\n",
      "Epoch: 4, Step: 750, Loss: 0.480943\n",
      "Epoch: 4, Step: 760, Loss: 0.479488\n",
      "Epoch: 4, Step: 770, Loss: 0.508854\n",
      "Epoch: 4, Step: 780, Loss: 0.505318\n",
      "Epoch: 4, Step: 790, Loss: 0.478109\n",
      "Epoch: 4, Step: 800, Loss: 0.462193\n",
      "Epoch: 4, Step: 810, Loss: 0.458041\n",
      "Epoch: 4, Step: 820, Loss: 0.45626\n",
      "Epoch: 4, Step: 830, Loss: 0.451607\n",
      "Epoch: 4, Step: 840, Loss: 0.448013\n",
      "Epoch: 4, Step: 850, Loss: 0.445592\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 5, Step: 500, Loss: 0.442151\n",
      "Epoch: 5, Step: 510, Loss: 0.440539\n",
      "Epoch: 5, Step: 520, Loss: 0.435352\n",
      "Epoch: 5, Step: 530, Loss: 0.431149\n",
      "Epoch: 5, Step: 540, Loss: 0.427421\n",
      "Epoch: 5, Step: 550, Loss: 0.424229\n",
      "Epoch: 5, Step: 560, Loss: 0.419006\n",
      "Epoch: 5, Step: 570, Loss: 0.415895\n",
      "Epoch: 5, Step: 580, Loss: 0.419515\n",
      "Epoch: 5, Step: 590, Loss: 0.466203\n",
      "Epoch: 5, Step: 600, Loss: 3.07397\n",
      "Epoch: 5, Step: 610, Loss: 3.18759\n",
      "Epoch: 5, Step: 620, Loss: 0.399957\n",
      "Epoch: 5, Step: 630, Loss: 0.39512\n",
      "Epoch: 5, Step: 640, Loss: 0.452113\n",
      "Epoch: 5, Step: 650, Loss: 0.456771\n",
      "Epoch: 5, Step: 660, Loss: 0.43811\n",
      "Epoch: 5, Step: 670, Loss: 0.426898\n",
      "Epoch: 5, Step: 680, Loss: 0.476786\n",
      "Epoch: 5, Step: 690, Loss: 0.379446\n",
      "Epoch: 5, Step: 700, Loss: 0.396584\n",
      "Epoch: 5, Step: 710, Loss: 0.390428\n",
      "Epoch: 5, Step: 720, Loss: 0.382731\n",
      "Epoch: 5, Step: 730, Loss: 0.370507\n",
      "Epoch: 5, Step: 740, Loss: 0.466207\n",
      "Epoch: 5, Step: 750, Loss: 0.458377\n",
      "Epoch: 5, Step: 760, Loss: 0.434822\n",
      "Epoch: 5, Step: 770, Loss: 0.46643\n",
      "Epoch: 5, Step: 780, Loss: 0.366431\n",
      "Epoch: 5, Step: 790, Loss: 0.370959\n",
      "Epoch: 5, Step: 800, Loss: 0.35784\n",
      "Epoch: 5, Step: 810, Loss: 0.352572\n",
      "Epoch: 5, Step: 820, Loss: 0.348205\n",
      "Epoch: 5, Step: 830, Loss: 0.344245\n",
      "Epoch: 5, Step: 840, Loss: 0.342418\n",
      "Epoch: 5, Step: 850, Loss: 0.33779\n",
      "Epoch: 5, Step: 860, Loss: 0.346022\n",
      "Epoch: 5, Step: 870, Loss: 0.33893\n",
      "Epoch: 5, Step: 880, Loss: 0.336663\n",
      "Epoch: 5, Step: 890, Loss: 0.322949\n",
      "Epoch: 5, Step: 900, Loss: 0.348668\n",
      "Epoch: 5, Step: 910, Loss: 0.383943\n",
      "Epoch: 5, Step: 920, Loss: 0.349383\n",
      "Epoch: 5, Step: 930, Loss: 0.871324\n",
      "Epoch: 5, Step: 940, Loss: 0.817244\n",
      "Epoch: 5, Step: 950, Loss: 0.446716\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 6, Step: 600, Loss: 0.342399\n",
      "Epoch: 6, Step: 610, Loss: 0.319751\n",
      "Epoch: 6, Step: 620, Loss: 0.342647\n",
      "Epoch: 6, Step: 630, Loss: 0.647822\n",
      "Epoch: 6, Step: 640, Loss: 1.72326\n",
      "Epoch: 6, Step: 650, Loss: 1.01323\n",
      "Epoch: 6, Step: 660, Loss: 0.377414\n",
      "Epoch: 6, Step: 670, Loss: 0.322072\n",
      "Epoch: 6, Step: 680, Loss: 0.286411\n",
      "Epoch: 6, Step: 690, Loss: 0.279749\n",
      "Epoch: 6, Step: 700, Loss: 0.287035\n",
      "Epoch: 6, Step: 710, Loss: 0.299787\n",
      "Epoch: 6, Step: 720, Loss: 0.324203\n",
      "Epoch: 6, Step: 730, Loss: 0.271282\n",
      "Epoch: 6, Step: 740, Loss: 0.329104\n",
      "Epoch: 6, Step: 750, Loss: 0.389381\n",
      "Epoch: 6, Step: 760, Loss: 0.664827\n",
      "Epoch: 6, Step: 770, Loss: 0.491561\n",
      "Epoch: 6, Step: 780, Loss: 0.279628\n",
      "Epoch: 6, Step: 790, Loss: 0.272043\n",
      "Epoch: 6, Step: 800, Loss: 0.265048\n",
      "Epoch: 6, Step: 810, Loss: 0.26164\n",
      "Epoch: 6, Step: 820, Loss: 0.262323\n",
      "Epoch: 6, Step: 830, Loss: 1.79785\n",
      "Epoch: 6, Step: 840, Loss: 4.28702\n",
      "Epoch: 6, Step: 850, Loss: 0.258381\n",
      "Epoch: 6, Step: 860, Loss: 0.246132\n",
      "Epoch: 6, Step: 870, Loss: 0.243399\n",
      "Epoch: 6, Step: 880, Loss: 0.244799\n",
      "Epoch: 6, Step: 890, Loss: 0.240952\n",
      "Epoch: 6, Step: 900, Loss: 0.239865\n",
      "Epoch: 6, Step: 910, Loss: 0.237166\n",
      "Epoch: 6, Step: 920, Loss: 0.235278\n",
      "Epoch: 6, Step: 930, Loss: 0.233828\n",
      "Epoch: 6, Step: 940, Loss: 0.228412\n",
      "Epoch: 6, Step: 950, Loss: 0.231498\n",
      "Epoch: 6, Step: 960, Loss: 0.263598\n",
      "Epoch: 6, Step: 970, Loss: 0.26093\n",
      "Epoch: 6, Step: 980, Loss: 0.228624\n",
      "Epoch: 6, Step: 990, Loss: 0.218686\n",
      "Epoch: 6, Step: 1000, Loss: 0.217448\n",
      "Epoch: 6, Step: 1010, Loss: 0.215959\n",
      "Epoch: 6, Step: 1020, Loss: 0.213436\n",
      "Epoch: 6, Step: 1030, Loss: 0.212482\n",
      "Epoch: 6, Step: 1040, Loss: 0.21028\n",
      "Epoch: 6, Step: 1050, Loss: 0.207839\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 7, Step: 700, Loss: 0.208172\n",
      "Epoch: 7, Step: 710, Loss: 0.20615\n",
      "Epoch: 7, Step: 720, Loss: 0.204467\n",
      "Epoch: 7, Step: 730, Loss: 0.20279\n",
      "Epoch: 7, Step: 740, Loss: 0.200748\n",
      "Epoch: 7, Step: 750, Loss: 0.199151\n",
      "Epoch: 7, Step: 760, Loss: 0.197542\n",
      "Epoch: 7, Step: 770, Loss: 0.221482\n",
      "Epoch: 7, Step: 780, Loss: 0.233871\n",
      "Epoch: 7, Step: 790, Loss: 3.88426\n",
      "Epoch: 7, Step: 800, Loss: 1.88994\n",
      "Epoch: 7, Step: 810, Loss: 0.19208\n",
      "Epoch: 7, Step: 820, Loss: 0.196066\n",
      "Epoch: 7, Step: 830, Loss: 0.244268\n",
      "Epoch: 7, Step: 840, Loss: 0.253606\n",
      "Epoch: 7, Step: 850, Loss: 0.20369\n",
      "Epoch: 7, Step: 860, Loss: 0.265795\n",
      "Epoch: 7, Step: 870, Loss: 0.292184\n",
      "Epoch: 7, Step: 880, Loss: 0.181579\n",
      "Epoch: 7, Step: 890, Loss: 0.226817\n",
      "Epoch: 7, Step: 900, Loss: 0.193814\n",
      "Epoch: 7, Step: 910, Loss: 0.191429\n",
      "Epoch: 7, Step: 920, Loss: 0.179985\n",
      "Epoch: 7, Step: 930, Loss: 0.287632\n",
      "Epoch: 7, Step: 940, Loss: 0.226885\n",
      "Epoch: 7, Step: 950, Loss: 0.291117\n",
      "Epoch: 7, Step: 960, Loss: 0.269283\n",
      "Epoch: 7, Step: 970, Loss: 0.193805\n",
      "Epoch: 7, Step: 980, Loss: 0.186073\n",
      "Epoch: 7, Step: 990, Loss: 0.184118\n",
      "Epoch: 7, Step: 1000, Loss: 0.181239\n",
      "Epoch: 7, Step: 1010, Loss: 0.180196\n",
      "Epoch: 7, Step: 1020, Loss: 0.178784\n",
      "Epoch: 7, Step: 1030, Loss: 0.178015\n",
      "Epoch: 7, Step: 1040, Loss: 0.175675\n",
      "Epoch: 7, Step: 1050, Loss: 0.192042\n",
      "Epoch: 7, Step: 1060, Loss: 0.188695\n",
      "Epoch: 7, Step: 1070, Loss: 0.179935\n",
      "Epoch: 7, Step: 1080, Loss: 0.164056\n",
      "Epoch: 7, Step: 1090, Loss: 0.216251\n",
      "Epoch: 7, Step: 1100, Loss: 0.217903\n",
      "Epoch: 7, Step: 1110, Loss: 0.316359\n",
      "Epoch: 7, Step: 1120, Loss: 0.775748\n",
      "Epoch: 7, Step: 1130, Loss: 0.576226\n",
      "Epoch: 7, Step: 1140, Loss: 0.277825\n",
      "Epoch: 7, Step: 1150, Loss: 0.195199\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 8, Step: 800, Loss: 0.159075\n",
      "Epoch: 8, Step: 810, Loss: 0.210168\n",
      "Epoch: 8, Step: 820, Loss: 0.71602\n",
      "Epoch: 8, Step: 830, Loss: 1.62216\n",
      "Epoch: 8, Step: 840, Loss: 0.635089\n",
      "Epoch: 8, Step: 850, Loss: 0.240755\n",
      "Epoch: 8, Step: 860, Loss: 0.146013\n",
      "Epoch: 8, Step: 870, Loss: 0.1445\n",
      "Epoch: 8, Step: 880, Loss: 0.139924\n",
      "Epoch: 8, Step: 890, Loss: 0.143971\n",
      "Epoch: 8, Step: 900, Loss: 0.180683\n",
      "Epoch: 8, Step: 910, Loss: 0.193573\n",
      "Epoch: 8, Step: 920, Loss: 0.136248\n",
      "Epoch: 8, Step: 930, Loss: 0.214485\n",
      "Epoch: 8, Step: 940, Loss: 0.382826\n",
      "Epoch: 8, Step: 950, Loss: 0.347166\n",
      "Epoch: 8, Step: 960, Loss: 0.326191\n",
      "Epoch: 8, Step: 970, Loss: 0.137216\n",
      "Epoch: 8, Step: 980, Loss: 0.136661\n",
      "Epoch: 8, Step: 990, Loss: 0.135335\n",
      "Epoch: 8, Step: 1000, Loss: 0.134218\n",
      "Epoch: 8, Step: 1010, Loss: 0.141632\n",
      "Epoch: 8, Step: 1020, Loss: 3.00752\n",
      "Epoch: 8, Step: 1030, Loss: 2.66714\n",
      "Epoch: 8, Step: 1040, Loss: 0.133536\n",
      "Epoch: 8, Step: 1050, Loss: 0.123483\n",
      "Epoch: 8, Step: 1060, Loss: 0.124427\n",
      "Epoch: 8, Step: 1070, Loss: 0.134847\n",
      "Epoch: 8, Step: 1080, Loss: 0.120556\n",
      "Epoch: 8, Step: 1090, Loss: 0.119825\n",
      "Epoch: 8, Step: 1100, Loss: 0.114365\n",
      "Epoch: 8, Step: 1110, Loss: 0.113706\n",
      "Epoch: 8, Step: 1120, Loss: 0.113604\n",
      "Epoch: 8, Step: 1130, Loss: 0.110905\n",
      "Epoch: 8, Step: 1140, Loss: 0.121104\n",
      "Epoch: 8, Step: 1150, Loss: 0.159227\n",
      "Epoch: 8, Step: 1160, Loss: 0.150646\n",
      "Epoch: 8, Step: 1170, Loss: 0.107976\n",
      "Epoch: 8, Step: 1180, Loss: 0.106971\n",
      "Epoch: 8, Step: 1190, Loss: 0.107084\n",
      "Epoch: 8, Step: 1200, Loss: 0.106195\n",
      "Epoch: 8, Step: 1210, Loss: 0.10514\n",
      "Epoch: 8, Step: 1220, Loss: 0.107364\n",
      "Epoch: 8, Step: 1230, Loss: 0.102545\n",
      "Epoch: 8, Step: 1240, Loss: 0.103039\n",
      "Epoch: 8, Step: 1250, Loss: 0.105658\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 9, Step: 900, Loss: 0.102701\n",
      "Epoch: 9, Step: 910, Loss: 0.103482\n",
      "Epoch: 9, Step: 920, Loss: 0.100728\n",
      "Epoch: 9, Step: 930, Loss: 0.0996862\n",
      "Epoch: 9, Step: 940, Loss: 0.0992581\n",
      "Epoch: 9, Step: 950, Loss: 0.0993547\n",
      "Epoch: 9, Step: 960, Loss: 0.133347\n",
      "Epoch: 9, Step: 970, Loss: 0.127457\n",
      "Epoch: 9, Step: 980, Loss: 5.09964\n",
      "Epoch: 9, Step: 990, Loss: 0.551435\n",
      "Epoch: 9, Step: 1000, Loss: 0.0942992\n",
      "Epoch: 9, Step: 1010, Loss: 0.11363\n",
      "Epoch: 9, Step: 1020, Loss: 0.161225\n",
      "Epoch: 9, Step: 1030, Loss: 0.170766\n",
      "Epoch: 9, Step: 1040, Loss: 0.100782\n",
      "Epoch: 9, Step: 1050, Loss: 0.180092\n",
      "Epoch: 9, Step: 1060, Loss: 0.159948\n",
      "Epoch: 9, Step: 1070, Loss: 0.0898851\n",
      "Epoch: 9, Step: 1080, Loss: 0.130196\n",
      "Epoch: 9, Step: 1090, Loss: 0.101886\n",
      "Epoch: 9, Step: 1100, Loss: 0.0986506\n",
      "Epoch: 9, Step: 1110, Loss: 0.0946777\n",
      "Epoch: 9, Step: 1120, Loss: 0.251633\n",
      "Epoch: 9, Step: 1130, Loss: 0.122269\n",
      "Epoch: 9, Step: 1140, Loss: 0.204075\n",
      "Epoch: 9, Step: 1150, Loss: 0.148857\n",
      "Epoch: 9, Step: 1160, Loss: 0.119439\n",
      "Epoch: 9, Step: 1170, Loss: 0.104284\n",
      "Epoch: 9, Step: 1180, Loss: 0.103718\n",
      "Epoch: 9, Step: 1190, Loss: 0.0976643\n",
      "Epoch: 9, Step: 1200, Loss: 0.0955406\n",
      "Epoch: 9, Step: 1210, Loss: 0.0943821\n",
      "Epoch: 9, Step: 1220, Loss: 0.0920943\n",
      "Epoch: 9, Step: 1230, Loss: 0.0899952\n",
      "Epoch: 9, Step: 1240, Loss: 0.102753\n",
      "Epoch: 9, Step: 1250, Loss: 0.100036\n",
      "Epoch: 9, Step: 1260, Loss: 0.086099\n",
      "Epoch: 9, Step: 1270, Loss: 0.0879348\n",
      "Epoch: 9, Step: 1280, Loss: 0.140233\n",
      "Epoch: 9, Step: 1290, Loss: 0.105484\n",
      "Epoch: 9, Step: 1300, Loss: 0.338727\n",
      "Epoch: 9, Step: 1310, Loss: 0.668352\n",
      "Epoch: 9, Step: 1320, Loss: 0.353549\n",
      "Epoch: 9, Step: 1330, Loss: 0.166475\n",
      "Epoch: 9, Step: 1340, Loss: 0.120495\n",
      "Epoch: 9, Step: 1350, Loss: 0.0799735\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 10, Step: 1000, Loss: 0.168982\n",
      "Epoch: 10, Step: 1010, Loss: 0.847611\n",
      "Epoch: 10, Step: 1020, Loss: 1.51486\n",
      "Epoch: 10, Step: 1030, Loss: 0.309014\n",
      "Epoch: 10, Step: 1040, Loss: 0.193424\n",
      "Epoch: 10, Step: 1050, Loss: 0.0692684\n",
      "Epoch: 10, Step: 1060, Loss: 0.072697\n",
      "Epoch: 10, Step: 1070, Loss: 0.0690755\n",
      "Epoch: 10, Step: 1080, Loss: 0.0796191\n",
      "Epoch: 10, Step: 1090, Loss: 0.0978958\n",
      "Epoch: 10, Step: 1100, Loss: 0.104632\n",
      "Epoch: 10, Step: 1110, Loss: 0.0692625\n",
      "Epoch: 10, Step: 1120, Loss: 0.191091\n",
      "Epoch: 10, Step: 1130, Loss: 0.457902\n",
      "Epoch: 10, Step: 1140, Loss: 0.170501\n",
      "Epoch: 10, Step: 1150, Loss: 0.25108\n",
      "Epoch: 10, Step: 1160, Loss: 0.0771283\n",
      "Epoch: 10, Step: 1170, Loss: 0.076665\n",
      "Epoch: 10, Step: 1180, Loss: 0.0758083\n",
      "Epoch: 10, Step: 1190, Loss: 0.0750329\n",
      "Epoch: 10, Step: 1200, Loss: 0.0810468\n",
      "Epoch: 10, Step: 1210, Loss: 4.42643\n",
      "Epoch: 10, Step: 1220, Loss: 1.17607\n",
      "Epoch: 10, Step: 1230, Loss: 0.0698571\n",
      "Epoch: 10, Step: 1240, Loss: 0.0611513\n",
      "Epoch: 10, Step: 1250, Loss: 0.0622241\n",
      "Epoch: 10, Step: 1260, Loss: 0.0666197\n",
      "Epoch: 10, Step: 1270, Loss: 0.0612646\n",
      "Epoch: 10, Step: 1280, Loss: 0.0615783\n",
      "Epoch: 10, Step: 1290, Loss: 0.0583801\n",
      "Epoch: 10, Step: 1300, Loss: 0.0587296\n",
      "Epoch: 10, Step: 1310, Loss: 0.0591819\n",
      "Epoch: 10, Step: 1320, Loss: 0.0592766\n",
      "Epoch: 10, Step: 1330, Loss: 0.0660078\n",
      "Epoch: 10, Step: 1340, Loss: 0.096423\n",
      "Epoch: 10, Step: 1350, Loss: 0.0829051\n",
      "Epoch: 10, Step: 1360, Loss: 0.054259\n",
      "Epoch: 10, Step: 1370, Loss: 0.0532233\n",
      "Epoch: 10, Step: 1380, Loss: 0.0531476\n",
      "Epoch: 10, Step: 1390, Loss: 0.0530113\n",
      "Epoch: 10, Step: 1400, Loss: 0.0513862\n",
      "Epoch: 10, Step: 1410, Loss: 0.0528054\n",
      "Epoch: 10, Step: 1420, Loss: 0.0506673\n",
      "Epoch: 10, Step: 1430, Loss: 0.0505125\n",
      "Epoch: 10, Step: 1440, Loss: 0.0508931\n",
      "Epoch: 10, Step: 1450, Loss: 0.0502763\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 11, Step: 1100, Loss: 0.0497349\n",
      "Epoch: 11, Step: 1110, Loss: 0.049065\n",
      "Epoch: 11, Step: 1120, Loss: 0.0487118\n",
      "Epoch: 11, Step: 1130, Loss: 0.0483604\n",
      "Epoch: 11, Step: 1140, Loss: 0.0493169\n",
      "Epoch: 11, Step: 1150, Loss: 0.0988534\n",
      "Epoch: 11, Step: 1160, Loss: 0.179805\n",
      "Epoch: 11, Step: 1170, Loss: 5.28799\n",
      "Epoch: 11, Step: 1180, Loss: 0.0652529\n",
      "Epoch: 11, Step: 1190, Loss: 0.0468853\n",
      "Epoch: 11, Step: 1200, Loss: 0.0814097\n",
      "Epoch: 11, Step: 1210, Loss: 0.115564\n",
      "Epoch: 11, Step: 1220, Loss: 0.112809\n",
      "Epoch: 11, Step: 1230, Loss: 0.049244\n",
      "Epoch: 11, Step: 1240, Loss: 0.172154\n",
      "Epoch: 11, Step: 1250, Loss: 0.0973778\n",
      "Epoch: 11, Step: 1260, Loss: 0.0444842\n",
      "Epoch: 11, Step: 1270, Loss: 0.10117\n",
      "Epoch: 11, Step: 1280, Loss: 0.0517854\n",
      "Epoch: 11, Step: 1290, Loss: 0.0617729\n",
      "Epoch: 11, Step: 1300, Loss: 0.0766769\n",
      "Epoch: 11, Step: 1310, Loss: 0.172627\n",
      "Epoch: 11, Step: 1320, Loss: 0.0903856\n",
      "Epoch: 11, Step: 1330, Loss: 0.179806\n",
      "Epoch: 11, Step: 1340, Loss: 0.097706\n",
      "Epoch: 11, Step: 1350, Loss: 0.0731222\n",
      "Epoch: 11, Step: 1360, Loss: 0.0615832\n",
      "Epoch: 11, Step: 1370, Loss: 0.057343\n",
      "Epoch: 11, Step: 1380, Loss: 0.0579926\n",
      "Epoch: 11, Step: 1390, Loss: 0.0574845\n",
      "Epoch: 11, Step: 1400, Loss: 0.0578428\n",
      "Epoch: 11, Step: 1410, Loss: 0.0571667\n",
      "Epoch: 11, Step: 1420, Loss: 0.0630715\n",
      "Epoch: 11, Step: 1430, Loss: 0.065169\n",
      "Epoch: 11, Step: 1440, Loss: 0.0749827\n",
      "Epoch: 11, Step: 1450, Loss: 0.0449659\n",
      "Epoch: 11, Step: 1460, Loss: 0.0629864\n",
      "Epoch: 11, Step: 1470, Loss: 0.133441\n",
      "Epoch: 11, Step: 1480, Loss: 0.0603255\n",
      "Epoch: 11, Step: 1490, Loss: 0.416797\n",
      "Epoch: 11, Step: 1500, Loss: 0.682172\n",
      "Epoch: 11, Step: 1510, Loss: 0.289478\n",
      "Epoch: 11, Step: 1520, Loss: 0.110719\n",
      "Epoch: 11, Step: 1530, Loss: 0.0843875\n",
      "Epoch: 11, Step: 1540, Loss: 0.0452801\n",
      "Epoch: 11, Step: 1550, Loss: 0.146596\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 12, Step: 1200, Loss: 0.992638\n",
      "Epoch: 12, Step: 1210, Loss: 1.37414\n",
      "Epoch: 12, Step: 1220, Loss: 0.125246\n",
      "Epoch: 12, Step: 1230, Loss: 0.149601\n",
      "Epoch: 12, Step: 1240, Loss: 0.0341791\n",
      "Epoch: 12, Step: 1250, Loss: 0.0408353\n",
      "Epoch: 12, Step: 1260, Loss: 0.0407279\n",
      "Epoch: 12, Step: 1270, Loss: 0.0511574\n",
      "Epoch: 12, Step: 1280, Loss: 0.0852955\n",
      "Epoch: 12, Step: 1290, Loss: 0.0715108\n",
      "Epoch: 12, Step: 1300, Loss: 0.0402412\n",
      "Epoch: 12, Step: 1310, Loss: 0.141784\n",
      "Epoch: 12, Step: 1320, Loss: 0.44176\n",
      "Epoch: 12, Step: 1330, Loss: 0.134355\n",
      "Epoch: 12, Step: 1340, Loss: 0.158553\n",
      "Epoch: 12, Step: 1350, Loss: 0.0398192\n",
      "Epoch: 12, Step: 1360, Loss: 0.0408487\n",
      "Epoch: 12, Step: 1370, Loss: 0.0416285\n",
      "Epoch: 12, Step: 1380, Loss: 0.0412444\n",
      "Epoch: 12, Step: 1390, Loss: 0.0675097\n",
      "Epoch: 12, Step: 1400, Loss: 5.19894\n",
      "Epoch: 12, Step: 1410, Loss: 0.273394\n",
      "Epoch: 12, Step: 1420, Loss: 0.041211\n",
      "Epoch: 12, Step: 1430, Loss: 0.0335701\n",
      "Epoch: 12, Step: 1440, Loss: 0.0385137\n",
      "Epoch: 12, Step: 1450, Loss: 0.0406256\n",
      "Epoch: 12, Step: 1460, Loss: 0.0359614\n",
      "Epoch: 12, Step: 1470, Loss: 0.0287174\n",
      "Epoch: 12, Step: 1480, Loss: 0.0285821\n",
      "Epoch: 12, Step: 1490, Loss: 0.0280823\n",
      "Epoch: 12, Step: 1500, Loss: 0.028484\n",
      "Epoch: 12, Step: 1510, Loss: 0.0292137\n",
      "Epoch: 12, Step: 1520, Loss: 0.051138\n",
      "Epoch: 12, Step: 1530, Loss: 0.0777672\n",
      "Epoch: 12, Step: 1540, Loss: 0.0531657\n",
      "Epoch: 12, Step: 1550, Loss: 0.0260842\n",
      "Epoch: 12, Step: 1560, Loss: 0.0264875\n",
      "Epoch: 12, Step: 1570, Loss: 0.0254753\n",
      "Epoch: 12, Step: 1580, Loss: 0.0262551\n",
      "Epoch: 12, Step: 1590, Loss: 0.0248758\n",
      "Epoch: 12, Step: 1600, Loss: 0.0271221\n",
      "Epoch: 12, Step: 1610, Loss: 0.0248159\n",
      "Epoch: 12, Step: 1620, Loss: 0.0261386\n",
      "Epoch: 12, Step: 1630, Loss: 0.0268884\n",
      "Epoch: 12, Step: 1640, Loss: 0.0264862\n",
      "Epoch: 12, Step: 1650, Loss: 0.0257773\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 13, Step: 1300, Loss: 0.0262298\n",
      "Epoch: 13, Step: 1310, Loss: 0.0253187\n",
      "Epoch: 13, Step: 1320, Loss: 0.0255292\n",
      "Epoch: 13, Step: 1330, Loss: 0.0288974\n",
      "Epoch: 13, Step: 1340, Loss: 0.0840096\n",
      "Epoch: 13, Step: 1350, Loss: 1.18061\n",
      "Epoch: 13, Step: 1360, Loss: 4.37506\n",
      "Epoch: 13, Step: 1370, Loss: 0.0300889\n",
      "Epoch: 13, Step: 1380, Loss: 0.0229816\n",
      "Epoch: 13, Step: 1390, Loss: 0.0697146\n",
      "Epoch: 13, Step: 1400, Loss: 0.0879901\n",
      "Epoch: 13, Step: 1410, Loss: 0.0895205\n",
      "Epoch: 13, Step: 1420, Loss: 0.0382928\n",
      "Epoch: 13, Step: 1430, Loss: 0.147369\n",
      "Epoch: 13, Step: 1440, Loss: 0.0409792\n",
      "Epoch: 13, Step: 1450, Loss: 0.0287699\n",
      "Epoch: 13, Step: 1460, Loss: 0.0617897\n",
      "Epoch: 13, Step: 1470, Loss: 0.0354957\n",
      "Epoch: 13, Step: 1480, Loss: 0.0307326\n",
      "Epoch: 13, Step: 1490, Loss: 0.0911665\n",
      "Epoch: 13, Step: 1500, Loss: 0.151642\n",
      "Epoch: 13, Step: 1510, Loss: 0.0810651\n",
      "Epoch: 13, Step: 1520, Loss: 0.134802\n",
      "Epoch: 13, Step: 1530, Loss: 0.0485812\n",
      "Epoch: 13, Step: 1540, Loss: 0.0614779\n",
      "Epoch: 13, Step: 1550, Loss: 0.0454584\n",
      "Epoch: 13, Step: 1560, Loss: 0.0409159\n",
      "Epoch: 13, Step: 1570, Loss: 0.0407504\n",
      "Epoch: 13, Step: 1580, Loss: 0.0407041\n",
      "Epoch: 13, Step: 1590, Loss: 0.0368206\n",
      "Epoch: 13, Step: 1600, Loss: 0.0347323\n",
      "Epoch: 13, Step: 1610, Loss: 0.0464167\n",
      "Epoch: 13, Step: 1620, Loss: 0.037667\n",
      "Epoch: 13, Step: 1630, Loss: 0.0431332\n",
      "Epoch: 13, Step: 1640, Loss: 0.0213895\n",
      "Epoch: 13, Step: 1650, Loss: 0.0411564\n",
      "Epoch: 13, Step: 1660, Loss: 0.0974726\n",
      "Epoch: 13, Step: 1670, Loss: 0.0269642\n",
      "Epoch: 13, Step: 1680, Loss: 0.465548\n",
      "Epoch: 13, Step: 1690, Loss: 0.589475\n",
      "Epoch: 13, Step: 1700, Loss: 0.200618\n",
      "Epoch: 13, Step: 1710, Loss: 0.0518488\n",
      "Epoch: 13, Step: 1720, Loss: 0.0452175\n",
      "Epoch: 13, Step: 1730, Loss: 0.0390458\n",
      "Epoch: 13, Step: 1740, Loss: 0.190147\n",
      "Epoch: 13, Step: 1750, Loss: 1.25458\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 14, Step: 1400, Loss: 1.12774\n",
      "Epoch: 14, Step: 1410, Loss: 0.0660268\n",
      "Epoch: 14, Step: 1420, Loss: 0.108938\n",
      "Epoch: 14, Step: 1430, Loss: 0.0176402\n",
      "Epoch: 14, Step: 1440, Loss: 0.0196666\n",
      "Epoch: 14, Step: 1450, Loss: 0.0242356\n",
      "Epoch: 14, Step: 1460, Loss: 0.0357618\n",
      "Epoch: 14, Step: 1470, Loss: 0.0692476\n",
      "Epoch: 14, Step: 1480, Loss: 0.0256613\n",
      "Epoch: 14, Step: 1490, Loss: 0.0290044\n",
      "Epoch: 14, Step: 1500, Loss: 0.145212\n",
      "Epoch: 14, Step: 1510, Loss: 0.436172\n",
      "Epoch: 14, Step: 1520, Loss: 0.251391\n",
      "Epoch: 14, Step: 1530, Loss: 0.0368991\n",
      "Epoch: 14, Step: 1540, Loss: 0.0295943\n",
      "Epoch: 14, Step: 1550, Loss: 0.0293806\n",
      "Epoch: 14, Step: 1560, Loss: 0.0296224\n",
      "Epoch: 14, Step: 1570, Loss: 0.0280607\n",
      "Epoch: 14, Step: 1580, Loss: 0.333865\n",
      "Epoch: 14, Step: 1590, Loss: 5.02145\n",
      "Epoch: 14, Step: 1600, Loss: 0.0774552\n",
      "Epoch: 14, Step: 1610, Loss: 0.0233775\n",
      "Epoch: 14, Step: 1620, Loss: 0.0176558\n",
      "Epoch: 14, Step: 1630, Loss: 0.0218681\n",
      "Epoch: 14, Step: 1640, Loss: 0.0195947\n",
      "Epoch: 14, Step: 1650, Loss: 0.0171755\n",
      "Epoch: 14, Step: 1660, Loss: 0.0175746\n",
      "Epoch: 14, Step: 1670, Loss: 0.0165284\n",
      "Epoch: 14, Step: 1680, Loss: 0.0162758\n",
      "Epoch: 14, Step: 1690, Loss: 0.0156786\n",
      "Epoch: 14, Step: 1700, Loss: 0.017089\n",
      "Epoch: 14, Step: 1710, Loss: 0.0384193\n",
      "Epoch: 14, Step: 1720, Loss: 0.0468494\n",
      "Epoch: 14, Step: 1730, Loss: 0.0279902\n",
      "Epoch: 14, Step: 1740, Loss: 0.0128352\n",
      "Epoch: 14, Step: 1750, Loss: 0.0124381\n",
      "Epoch: 14, Step: 1760, Loss: 0.012431\n",
      "Epoch: 14, Step: 1770, Loss: 0.0121288\n",
      "Epoch: 14, Step: 1780, Loss: 0.0116042\n",
      "Epoch: 14, Step: 1790, Loss: 0.0124052\n",
      "Epoch: 14, Step: 1800, Loss: 0.0112413\n",
      "Epoch: 14, Step: 1810, Loss: 0.0120624\n",
      "Epoch: 14, Step: 1820, Loss: 0.011611\n",
      "Epoch: 14, Step: 1830, Loss: 0.0116573\n",
      "Epoch: 14, Step: 1840, Loss: 0.0113453\n",
      "Epoch: 14, Step: 1850, Loss: 0.0106428\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 15, Step: 1500, Loss: 0.0105966\n",
      "Epoch: 15, Step: 1510, Loss: 0.0106597\n",
      "Epoch: 15, Step: 1520, Loss: 0.0147569\n",
      "Epoch: 15, Step: 1530, Loss: 0.0713208\n",
      "Epoch: 15, Step: 1540, Loss: 2.36142\n",
      "Epoch: 15, Step: 1550, Loss: 3.04065\n",
      "Epoch: 15, Step: 1560, Loss: 0.0128297\n",
      "Epoch: 15, Step: 1570, Loss: 0.0102843\n",
      "Epoch: 15, Step: 1580, Loss: 0.0746467\n",
      "Epoch: 15, Step: 1590, Loss: 0.0825431\n",
      "Epoch: 15, Step: 1600, Loss: 0.071615\n",
      "Epoch: 15, Step: 1610, Loss: 0.0536539\n",
      "Epoch: 15, Step: 1620, Loss: 0.131776\n",
      "Epoch: 15, Step: 1630, Loss: 0.0138329\n",
      "Epoch: 15, Step: 1640, Loss: 0.0367014\n",
      "Epoch: 15, Step: 1650, Loss: 0.0377825\n",
      "Epoch: 15, Step: 1660, Loss: 0.0231071\n",
      "Epoch: 15, Step: 1670, Loss: 0.0228768\n",
      "Epoch: 15, Step: 1680, Loss: 0.0865012\n",
      "Epoch: 15, Step: 1690, Loss: 0.0959776\n",
      "Epoch: 15, Step: 1700, Loss: 0.103955\n",
      "Epoch: 15, Step: 1710, Loss: 0.148881\n",
      "Epoch: 15, Step: 1720, Loss: 0.0226481\n",
      "Epoch: 15, Step: 1730, Loss: 0.0349945\n",
      "Epoch: 15, Step: 1740, Loss: 0.0261094\n",
      "Epoch: 15, Step: 1750, Loss: 0.0250244\n",
      "Epoch: 15, Step: 1760, Loss: 0.0264414\n",
      "Epoch: 15, Step: 1770, Loss: 0.0270801\n",
      "Epoch: 15, Step: 1780, Loss: 0.0269621\n",
      "Epoch: 15, Step: 1790, Loss: 0.0263957\n",
      "Epoch: 15, Step: 1800, Loss: 0.0412878\n",
      "Epoch: 15, Step: 1810, Loss: 0.0347494\n",
      "Epoch: 15, Step: 1820, Loss: 0.0354264\n",
      "Epoch: 15, Step: 1830, Loss: 0.0121295\n",
      "Epoch: 15, Step: 1840, Loss: 0.0489853\n",
      "Epoch: 15, Step: 1850, Loss: 0.100518\n",
      "Epoch: 15, Step: 1860, Loss: 0.0393395\n",
      "Epoch: 15, Step: 1870, Loss: 0.600767\n",
      "Epoch: 15, Step: 1880, Loss: 0.559679\n",
      "Epoch: 15, Step: 1890, Loss: 0.170223\n",
      "Epoch: 15, Step: 1900, Loss: 0.0525386\n",
      "Epoch: 15, Step: 1910, Loss: 0.0325255\n",
      "Epoch: 15, Step: 1920, Loss: 0.0408674\n",
      "Epoch: 15, Step: 1930, Loss: 0.300817\n",
      "Epoch: 15, Step: 1940, Loss: 1.38975\n",
      "Epoch: 15, Step: 1950, Loss: 0.781148\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 16, Step: 1600, Loss: 0.0926487\n",
      "Epoch: 16, Step: 1610, Loss: 0.0574182\n",
      "Epoch: 16, Step: 1620, Loss: 0.0112757\n",
      "Epoch: 16, Step: 1630, Loss: 0.00908255\n",
      "Epoch: 16, Step: 1640, Loss: 0.0155352\n",
      "Epoch: 16, Step: 1650, Loss: 0.0396421\n",
      "Epoch: 16, Step: 1660, Loss: 0.0760672\n",
      "Epoch: 16, Step: 1670, Loss: 0.00831755\n",
      "Epoch: 16, Step: 1680, Loss: 0.0504987\n",
      "Epoch: 16, Step: 1690, Loss: 0.134613\n",
      "Epoch: 16, Step: 1700, Loss: 0.364117\n",
      "Epoch: 16, Step: 1710, Loss: 0.21283\n",
      "Epoch: 16, Step: 1720, Loss: 0.0201654\n",
      "Epoch: 16, Step: 1730, Loss: 0.0152385\n",
      "Epoch: 16, Step: 1740, Loss: 0.0146021\n",
      "Epoch: 16, Step: 1750, Loss: 0.015466\n",
      "Epoch: 16, Step: 1760, Loss: 0.0186779\n",
      "Epoch: 16, Step: 1770, Loss: 1.19491\n",
      "Epoch: 16, Step: 1780, Loss: 4.24975\n",
      "Epoch: 16, Step: 1790, Loss: 0.0221178\n",
      "Epoch: 16, Step: 1800, Loss: 0.0114362\n",
      "Epoch: 16, Step: 1810, Loss: 0.0124525\n",
      "Epoch: 16, Step: 1820, Loss: 0.0181629\n",
      "Epoch: 16, Step: 1830, Loss: 0.0117975\n",
      "Epoch: 16, Step: 1840, Loss: 0.0116017\n",
      "Epoch: 16, Step: 1850, Loss: 0.00727387\n",
      "Epoch: 16, Step: 1860, Loss: 0.00675627\n",
      "Epoch: 16, Step: 1870, Loss: 0.00703146\n",
      "Epoch: 16, Step: 1880, Loss: 0.00547078\n",
      "Epoch: 16, Step: 1890, Loss: 0.0098822\n",
      "Epoch: 16, Step: 1900, Loss: 0.0483553\n",
      "Epoch: 16, Step: 1910, Loss: 0.0493392\n",
      "Epoch: 16, Step: 1920, Loss: 0.0159704\n",
      "Epoch: 16, Step: 1930, Loss: 0.00510104\n",
      "Epoch: 16, Step: 1940, Loss: 0.00570769\n",
      "Epoch: 16, Step: 1950, Loss: 0.00590901\n",
      "Epoch: 16, Step: 1960, Loss: 0.00473119\n",
      "Epoch: 16, Step: 1970, Loss: 0.00527021\n",
      "Epoch: 16, Step: 1980, Loss: 0.00536705\n",
      "Epoch: 16, Step: 1990, Loss: 0.00483625\n",
      "Epoch: 16, Step: 2000, Loss: 0.00647829\n",
      "Epoch: 16, Step: 2010, Loss: 0.00557215\n",
      "Epoch: 16, Step: 2020, Loss: 0.00684982\n",
      "Epoch: 16, Step: 2030, Loss: 0.00640565\n",
      "Epoch: 16, Step: 2040, Loss: 0.00664938\n",
      "Epoch: 16, Step: 2050, Loss: 0.00611337\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 17, Step: 1700, Loss: 0.00691098\n",
      "Epoch: 17, Step: 1710, Loss: 0.0348065\n",
      "Epoch: 17, Step: 1720, Loss: 0.0459765\n",
      "Epoch: 17, Step: 1730, Loss: 3.4576\n",
      "Epoch: 17, Step: 1740, Loss: 2.06981\n",
      "Epoch: 17, Step: 1750, Loss: 0.0071896\n",
      "Epoch: 17, Step: 1760, Loss: 0.00891127\n",
      "Epoch: 17, Step: 1770, Loss: 0.0670841\n",
      "Epoch: 17, Step: 1780, Loss: 0.0818646\n",
      "Epoch: 17, Step: 1790, Loss: 0.0375164\n",
      "Epoch: 17, Step: 1800, Loss: 0.0685504\n",
      "Epoch: 17, Step: 1810, Loss: 0.101316\n",
      "Epoch: 17, Step: 1820, Loss: 0.00669764\n",
      "Epoch: 17, Step: 1830, Loss: 0.0387661\n",
      "Epoch: 17, Step: 1840, Loss: 0.0228062\n",
      "Epoch: 17, Step: 1850, Loss: 0.0189272\n",
      "Epoch: 17, Step: 1860, Loss: 0.00966586\n",
      "Epoch: 17, Step: 1870, Loss: 0.132278\n",
      "Epoch: 17, Step: 1880, Loss: 0.0780571\n",
      "Epoch: 17, Step: 1890, Loss: 0.10334\n",
      "Epoch: 17, Step: 1900, Loss: 0.101689\n",
      "Epoch: 17, Step: 1910, Loss: 0.0314626\n",
      "Epoch: 17, Step: 1920, Loss: 0.0297939\n",
      "Epoch: 17, Step: 1930, Loss: 0.0284622\n",
      "Epoch: 17, Step: 1940, Loss: 0.0259932\n",
      "Epoch: 17, Step: 1950, Loss: 0.0265147\n",
      "Epoch: 17, Step: 1960, Loss: 0.0258161\n",
      "Epoch: 17, Step: 1970, Loss: 0.0253264\n",
      "Epoch: 17, Step: 1980, Loss: 0.0244121\n",
      "Epoch: 17, Step: 1990, Loss: 0.0351732\n",
      "Epoch: 17, Step: 2000, Loss: 0.0288735\n",
      "Epoch: 17, Step: 2010, Loss: 0.0240376\n",
      "Epoch: 17, Step: 2020, Loss: 0.0113519\n",
      "Epoch: 17, Step: 2030, Loss: 0.0475066\n",
      "Epoch: 17, Step: 2040, Loss: 0.0645658\n",
      "Epoch: 17, Step: 2050, Loss: 0.114677\n",
      "Epoch: 17, Step: 2060, Loss: 0.569907\n",
      "Epoch: 17, Step: 2070, Loss: 0.410775\n",
      "Epoch: 17, Step: 2080, Loss: 0.115092\n",
      "Epoch: 17, Step: 2090, Loss: 0.0403484\n",
      "Epoch: 17, Step: 2100, Loss: 0.0191117\n",
      "Epoch: 17, Step: 2110, Loss: 0.0757201\n",
      "Epoch: 17, Step: 2120, Loss: 0.537411\n",
      "Epoch: 17, Step: 2130, Loss: 1.45527\n",
      "Epoch: 17, Step: 2140, Loss: 0.551887\n",
      "Epoch: 17, Step: 2150, Loss: 0.115257\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 18, Step: 1800, Loss: 0.0176614\n",
      "Epoch: 18, Step: 1810, Loss: 0.00854993\n",
      "Epoch: 18, Step: 1820, Loss: 0.0039245\n",
      "Epoch: 18, Step: 1830, Loss: 0.0119508\n",
      "Epoch: 18, Step: 1840, Loss: 0.0356338\n",
      "Epoch: 18, Step: 1850, Loss: 0.054587\n",
      "Epoch: 18, Step: 1860, Loss: 0.00521287\n",
      "Epoch: 18, Step: 1870, Loss: 0.0854069\n",
      "Epoch: 18, Step: 1880, Loss: 0.213636\n",
      "Epoch: 18, Step: 1890, Loss: 0.300845\n",
      "Epoch: 18, Step: 1900, Loss: 0.223161\n",
      "Epoch: 18, Step: 1910, Loss: 0.0184908\n",
      "Epoch: 18, Step: 1920, Loss: 0.0172996\n",
      "Epoch: 18, Step: 1930, Loss: 0.0170627\n",
      "Epoch: 18, Step: 1940, Loss: 0.0176456\n",
      "Epoch: 18, Step: 1950, Loss: 0.0260503\n",
      "Epoch: 18, Step: 1960, Loss: 2.46288\n",
      "Epoch: 18, Step: 1970, Loss: 2.90178\n",
      "Epoch: 18, Step: 1980, Loss: 0.0188585\n",
      "Epoch: 18, Step: 1990, Loss: 0.00861497\n",
      "Epoch: 18, Step: 2000, Loss: 0.00778733\n",
      "Epoch: 18, Step: 2010, Loss: 0.0148208\n",
      "Epoch: 18, Step: 2020, Loss: 0.00559732\n",
      "Epoch: 18, Step: 2030, Loss: 0.00776424\n",
      "Epoch: 18, Step: 2040, Loss: 0.00456704\n",
      "Epoch: 18, Step: 2050, Loss: 0.00575621\n",
      "Epoch: 18, Step: 2060, Loss: 0.00668323\n",
      "Epoch: 18, Step: 2070, Loss: 0.00394475\n",
      "Epoch: 18, Step: 2080, Loss: 0.0107646\n",
      "Epoch: 18, Step: 2090, Loss: 0.0364051\n",
      "Epoch: 18, Step: 2100, Loss: 0.0354974\n",
      "Epoch: 18, Step: 2110, Loss: 0.00465633\n",
      "Epoch: 18, Step: 2120, Loss: 0.00237114\n",
      "Epoch: 18, Step: 2130, Loss: 0.00327623\n",
      "Epoch: 18, Step: 2140, Loss: 0.00290731\n",
      "Epoch: 18, Step: 2150, Loss: 0.00215968\n",
      "Epoch: 18, Step: 2160, Loss: 0.00344177\n",
      "Epoch: 18, Step: 2170, Loss: 0.00175152\n",
      "Epoch: 18, Step: 2180, Loss: 0.00193516\n",
      "Epoch: 18, Step: 2190, Loss: 0.00309933\n",
      "Epoch: 18, Step: 2200, Loss: 0.00230912\n",
      "Epoch: 18, Step: 2210, Loss: 0.00267248\n",
      "Epoch: 18, Step: 2220, Loss: 0.00209444\n",
      "Epoch: 18, Step: 2230, Loss: 0.0019596\n",
      "Epoch: 18, Step: 2240, Loss: 0.00196445\n",
      "Epoch: 18, Step: 2250, Loss: 0.00189256\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 19, Step: 1900, Loss: 0.0303435\n",
      "Epoch: 19, Step: 1910, Loss: 0.038436\n",
      "Epoch: 19, Step: 1920, Loss: 4.64497\n",
      "Epoch: 19, Step: 1930, Loss: 0.750983\n",
      "Epoch: 19, Step: 1940, Loss: 0.00261802\n",
      "Epoch: 19, Step: 1950, Loss: 0.021763\n",
      "Epoch: 19, Step: 1960, Loss: 0.0779053\n",
      "Epoch: 19, Step: 1970, Loss: 0.0929521\n",
      "Epoch: 19, Step: 1980, Loss: 0.0169788\n",
      "Epoch: 19, Step: 1990, Loss: 0.080881\n",
      "Epoch: 19, Step: 2000, Loss: 0.0734262\n",
      "Epoch: 19, Step: 2010, Loss: 0.00343563\n",
      "Epoch: 19, Step: 2020, Loss: 0.0508107\n",
      "Epoch: 19, Step: 2030, Loss: 0.0127739\n",
      "Epoch: 19, Step: 2040, Loss: 0.0186112\n",
      "Epoch: 19, Step: 2050, Loss: 0.00607849\n",
      "Epoch: 19, Step: 2060, Loss: 0.140168\n",
      "Epoch: 19, Step: 2070, Loss: 0.0404456\n",
      "Epoch: 19, Step: 2080, Loss: 0.149989\n",
      "Epoch: 19, Step: 2090, Loss: 0.0909225\n",
      "Epoch: 19, Step: 2100, Loss: 0.0268521\n",
      "Epoch: 19, Step: 2110, Loss: 0.0164364\n",
      "Epoch: 19, Step: 2120, Loss: 0.0180505\n",
      "Epoch: 19, Step: 2130, Loss: 0.0157225\n",
      "Epoch: 19, Step: 2140, Loss: 0.0167737\n",
      "Epoch: 19, Step: 2150, Loss: 0.0179622\n",
      "Epoch: 19, Step: 2160, Loss: 0.0190858\n",
      "Epoch: 19, Step: 2170, Loss: 0.0187857\n",
      "Epoch: 19, Step: 2180, Loss: 0.0350252\n",
      "Epoch: 19, Step: 2190, Loss: 0.0317706\n",
      "Epoch: 19, Step: 2200, Loss: 0.0182108\n",
      "Epoch: 19, Step: 2210, Loss: 0.0163788\n",
      "Epoch: 19, Step: 2220, Loss: 0.0766252\n",
      "Epoch: 19, Step: 2230, Loss: 0.0447506\n",
      "Epoch: 19, Step: 2240, Loss: 0.25813\n",
      "Epoch: 19, Step: 2250, Loss: 0.626114\n",
      "Epoch: 19, Step: 2260, Loss: 0.339598\n",
      "Epoch: 19, Step: 2270, Loss: 0.115766\n",
      "Epoch: 19, Step: 2280, Loss: 0.057174\n",
      "Epoch: 19, Step: 2290, Loss: 0.00986979\n",
      "Epoch: 19, Step: 2300, Loss: 0.0862553\n",
      "Epoch: 19, Step: 2310, Loss: 0.702714\n",
      "Epoch: 19, Step: 2320, Loss: 1.41153\n",
      "Epoch: 19, Step: 2330, Loss: 0.286233\n",
      "Epoch: 19, Step: 2340, Loss: 0.13524\n",
      "Epoch: 19, Step: 2350, Loss: 0.00424073\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 20, Step: 2000, Loss: 0.0060462\n",
      "Epoch: 20, Step: 2010, Loss: 0.00209858\n",
      "Epoch: 20, Step: 2020, Loss: 0.0142735\n",
      "Epoch: 20, Step: 2030, Loss: 0.0410846\n",
      "Epoch: 20, Step: 2040, Loss: 0.0492965\n",
      "Epoch: 20, Step: 2050, Loss: 0.0085918\n",
      "Epoch: 20, Step: 2060, Loss: 0.106111\n",
      "Epoch: 20, Step: 2070, Loss: 0.368071\n",
      "Epoch: 20, Step: 2080, Loss: 0.096231\n",
      "Epoch: 20, Step: 2090, Loss: 0.17428\n",
      "Epoch: 20, Step: 2100, Loss: 0.0079464\n",
      "Epoch: 20, Step: 2110, Loss: 0.00879902\n",
      "Epoch: 20, Step: 2120, Loss: 0.00993994\n",
      "Epoch: 20, Step: 2130, Loss: 0.0100134\n",
      "Epoch: 20, Step: 2140, Loss: 0.0184953\n",
      "Epoch: 20, Step: 2150, Loss: 4.01777\n",
      "Epoch: 20, Step: 2160, Loss: 1.46516\n",
      "Epoch: 20, Step: 2170, Loss: 0.0143801\n",
      "Epoch: 20, Step: 2180, Loss: 0.00594268\n",
      "Epoch: 20, Step: 2190, Loss: 0.00771251\n",
      "Epoch: 20, Step: 2200, Loss: 0.0157109\n",
      "Epoch: 20, Step: 2210, Loss: 0.00687274\n",
      "Epoch: 20, Step: 2220, Loss: 0.0039663\n",
      "Epoch: 20, Step: 2230, Loss: 0.00156735\n",
      "Epoch: 20, Step: 2240, Loss: 0.00252188\n",
      "Epoch: 20, Step: 2250, Loss: 0.00307366\n",
      "Epoch: 20, Step: 2260, Loss: 0.0019593\n",
      "Epoch: 20, Step: 2270, Loss: 0.0155175\n",
      "Epoch: 20, Step: 2280, Loss: 0.0529155\n",
      "Epoch: 20, Step: 2290, Loss: 0.037169\n",
      "Epoch: 20, Step: 2300, Loss: 0.00122636\n",
      "Epoch: 20, Step: 2310, Loss: 0.00163758\n",
      "Epoch: 20, Step: 2320, Loss: 0.000743074\n",
      "Epoch: 20, Step: 2330, Loss: 0.00192963\n",
      "Epoch: 20, Step: 2340, Loss: 0.000735581\n",
      "Epoch: 20, Step: 2350, Loss: 0.00163295\n",
      "Epoch: 20, Step: 2360, Loss: 0.000963139\n",
      "Epoch: 20, Step: 2370, Loss: 0.000870568\n",
      "Epoch: 20, Step: 2380, Loss: 0.00226854\n",
      "Epoch: 20, Step: 2390, Loss: 0.00188277\n",
      "Epoch: 20, Step: 2400, Loss: 0.00221043\n",
      "Epoch: 20, Step: 2410, Loss: 0.00166835\n",
      "Epoch: 20, Step: 2420, Loss: 0.00264036\n",
      "Epoch: 20, Step: 2430, Loss: 0.00256141\n",
      "Epoch: 20, Step: 2440, Loss: 0.00490359\n",
      "Epoch: 20, Step: 2450, Loss: 0.0516285\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 21, Step: 2100, Loss: 0.0662876\n",
      "Epoch: 21, Step: 2110, Loss: 5.4688\n",
      "Epoch: 21, Step: 2120, Loss: 0.0632666\n",
      "Epoch: 21, Step: 2130, Loss: 0.00243911\n",
      "Epoch: 21, Step: 2140, Loss: 0.0274124\n",
      "Epoch: 21, Step: 2150, Loss: 0.0642199\n",
      "Epoch: 21, Step: 2160, Loss: 0.0690196\n",
      "Epoch: 21, Step: 2170, Loss: 0.00615316\n",
      "Epoch: 21, Step: 2180, Loss: 0.110159\n",
      "Epoch: 21, Step: 2190, Loss: 0.0551972\n",
      "Epoch: 21, Step: 2200, Loss: 0.0021052\n",
      "Epoch: 21, Step: 2210, Loss: 0.0483963\n",
      "Epoch: 21, Step: 2220, Loss: 0.0149276\n",
      "Epoch: 21, Step: 2230, Loss: 0.0132817\n",
      "Epoch: 21, Step: 2240, Loss: 0.0319816\n",
      "Epoch: 21, Step: 2250, Loss: 0.151926\n",
      "Epoch: 21, Step: 2260, Loss: 0.0411411\n",
      "Epoch: 21, Step: 2270, Loss: 0.121031\n",
      "Epoch: 21, Step: 2280, Loss: 0.0551383\n",
      "Epoch: 21, Step: 2290, Loss: 0.0404458\n",
      "Epoch: 21, Step: 2300, Loss: 0.0259877\n",
      "Epoch: 21, Step: 2310, Loss: 0.021571\n",
      "Epoch: 21, Step: 2320, Loss: 0.0225136\n",
      "Epoch: 21, Step: 2330, Loss: 0.0233826\n",
      "Epoch: 21, Step: 2340, Loss: 0.0237309\n",
      "Epoch: 21, Step: 2350, Loss: 0.0231215\n",
      "Epoch: 21, Step: 2360, Loss: 0.0274777\n",
      "Epoch: 21, Step: 2370, Loss: 0.0333137\n",
      "Epoch: 21, Step: 2380, Loss: 0.0411151\n",
      "Epoch: 21, Step: 2390, Loss: 0.00892559\n",
      "Epoch: 21, Step: 2400, Loss: 0.0197198\n",
      "Epoch: 21, Step: 2410, Loss: 0.0824946\n",
      "Epoch: 21, Step: 2420, Loss: 0.0239422\n",
      "Epoch: 21, Step: 2430, Loss: 0.321493\n",
      "Epoch: 21, Step: 2440, Loss: 0.604823\n",
      "Epoch: 21, Step: 2450, Loss: 0.229687\n",
      "Epoch: 21, Step: 2460, Loss: 0.0675712\n",
      "Epoch: 21, Step: 2470, Loss: 0.0364244\n",
      "Epoch: 21, Step: 2480, Loss: 0.0172669\n",
      "Epoch: 21, Step: 2490, Loss: 0.126037\n",
      "Epoch: 21, Step: 2500, Loss: 0.948659\n",
      "Epoch: 21, Step: 2510, Loss: 1.43959\n",
      "Epoch: 21, Step: 2520, Loss: 0.120192\n",
      "Epoch: 21, Step: 2530, Loss: 0.119386\n",
      "Epoch: 21, Step: 2540, Loss: 0.00151899\n",
      "Epoch: 21, Step: 2550, Loss: 0.00579201\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 22, Step: 2200, Loss: 0.0074384\n",
      "Epoch: 22, Step: 2210, Loss: 0.0142549\n",
      "Epoch: 22, Step: 2220, Loss: 0.0407428\n",
      "Epoch: 22, Step: 2230, Loss: 0.0366856\n",
      "Epoch: 22, Step: 2240, Loss: 0.00570867\n",
      "Epoch: 22, Step: 2250, Loss: 0.125473\n",
      "Epoch: 22, Step: 2260, Loss: 0.418401\n",
      "Epoch: 22, Step: 2270, Loss: 0.102153\n",
      "Epoch: 22, Step: 2280, Loss: 0.15689\n",
      "Epoch: 22, Step: 2290, Loss: 0.015637\n",
      "Epoch: 22, Step: 2300, Loss: 0.015889\n",
      "Epoch: 22, Step: 2310, Loss: 0.0151818\n",
      "Epoch: 22, Step: 2320, Loss: 0.0148249\n",
      "Epoch: 22, Step: 2330, Loss: 0.0289539\n",
      "Epoch: 22, Step: 2340, Loss: 4.9871\n",
      "Epoch: 22, Step: 2350, Loss: 0.363813\n",
      "Epoch: 22, Step: 2360, Loss: 0.0160846\n",
      "Epoch: 22, Step: 2370, Loss: 0.00725063\n",
      "Epoch: 22, Step: 2380, Loss: 0.0119988\n",
      "Epoch: 22, Step: 2390, Loss: 0.0156428\n",
      "Epoch: 22, Step: 2400, Loss: 0.00707606\n",
      "Epoch: 22, Step: 2410, Loss: 0.00311725\n",
      "Epoch: 22, Step: 2420, Loss: 0.00233831\n",
      "Epoch: 22, Step: 2430, Loss: 0.00273494\n",
      "Epoch: 22, Step: 2440, Loss: 0.00473691\n",
      "Epoch: 22, Step: 2450, Loss: 0.00608483\n",
      "Epoch: 22, Step: 2460, Loss: 0.0135493\n",
      "Epoch: 22, Step: 2470, Loss: 0.0368492\n",
      "Epoch: 22, Step: 2480, Loss: 0.0200746\n",
      "Epoch: 22, Step: 2490, Loss: 0.00332013\n",
      "Epoch: 22, Step: 2500, Loss: 0.00106692\n",
      "Epoch: 22, Step: 2510, Loss: 0.00223614\n",
      "Epoch: 22, Step: 2520, Loss: 0.00193707\n",
      "Epoch: 22, Step: 2530, Loss: 0.000457319\n",
      "Epoch: 22, Step: 2540, Loss: 0.0027384\n",
      "Epoch: 22, Step: 2550, Loss: 0.000469414\n",
      "Epoch: 22, Step: 2560, Loss: 0.000983223\n",
      "Epoch: 22, Step: 2570, Loss: 0.00153224\n",
      "Epoch: 22, Step: 2580, Loss: 0.00163139\n",
      "Epoch: 22, Step: 2590, Loss: 0.00108048\n",
      "Epoch: 22, Step: 2600, Loss: 0.000844251\n",
      "Epoch: 22, Step: 2610, Loss: 0.000690798\n",
      "Epoch: 22, Step: 2620, Loss: 0.000954897\n",
      "Epoch: 22, Step: 2630, Loss: 0.00370043\n",
      "Epoch: 22, Step: 2640, Loss: 0.0612345\n",
      "Epoch: 22, Step: 2650, Loss: 0.78856\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 23, Step: 2300, Loss: 4.59354\n",
      "Epoch: 23, Step: 2310, Loss: 0.00572962\n",
      "Epoch: 23, Step: 2320, Loss: 0.00116486\n",
      "Epoch: 23, Step: 2330, Loss: 0.0485564\n",
      "Epoch: 23, Step: 2340, Loss: 0.0747438\n",
      "Epoch: 23, Step: 2350, Loss: 0.0781965\n",
      "Epoch: 23, Step: 2360, Loss: 0.00959469\n",
      "Epoch: 23, Step: 2370, Loss: 0.116431\n",
      "Epoch: 23, Step: 2380, Loss: 0.0260462\n",
      "Epoch: 23, Step: 2390, Loss: 0.00525073\n",
      "Epoch: 23, Step: 2400, Loss: 0.0419992\n",
      "Epoch: 23, Step: 2410, Loss: 0.013306\n",
      "Epoch: 23, Step: 2420, Loss: 0.0145264\n",
      "Epoch: 23, Step: 2430, Loss: 0.0569753\n",
      "Epoch: 23, Step: 2440, Loss: 0.118432\n",
      "Epoch: 23, Step: 2450, Loss: 0.0690839\n",
      "Epoch: 23, Step: 2460, Loss: 0.13741\n",
      "Epoch: 23, Step: 2470, Loss: 0.0398279\n",
      "Epoch: 23, Step: 2480, Loss: 0.028756\n",
      "Epoch: 23, Step: 2490, Loss: 0.0154683\n",
      "Epoch: 23, Step: 2500, Loss: 0.0128566\n",
      "Epoch: 23, Step: 2510, Loss: 0.0149879\n",
      "Epoch: 23, Step: 2520, Loss: 0.0154712\n",
      "Epoch: 23, Step: 2530, Loss: 0.0149392\n",
      "Epoch: 23, Step: 2540, Loss: 0.0155574\n",
      "Epoch: 23, Step: 2550, Loss: 0.0279115\n",
      "Epoch: 23, Step: 2560, Loss: 0.0241293\n",
      "Epoch: 23, Step: 2570, Loss: 0.0340185\n",
      "Epoch: 23, Step: 2580, Loss: 0.00493266\n",
      "Epoch: 23, Step: 2590, Loss: 0.0291536\n",
      "Epoch: 23, Step: 2600, Loss: 0.0946817\n",
      "Epoch: 23, Step: 2610, Loss: 0.0146659\n",
      "Epoch: 23, Step: 2620, Loss: 0.45256\n",
      "Epoch: 23, Step: 2630, Loss: 0.615842\n",
      "Epoch: 23, Step: 2640, Loss: 0.208716\n",
      "Epoch: 23, Step: 2650, Loss: 0.0491403\n",
      "Epoch: 23, Step: 2660, Loss: 0.0401079\n",
      "Epoch: 23, Step: 2670, Loss: 0.0148672\n",
      "Epoch: 23, Step: 2680, Loss: 0.141595\n",
      "Epoch: 23, Step: 2690, Loss: 1.14788\n",
      "Epoch: 23, Step: 2700, Loss: 1.16902\n",
      "Epoch: 23, Step: 2710, Loss: 0.0534668\n",
      "Epoch: 23, Step: 2720, Loss: 0.111329\n",
      "Epoch: 23, Step: 2730, Loss: 0.00251686\n",
      "Epoch: 23, Step: 2740, Loss: 0.00376632\n",
      "Epoch: 23, Step: 2750, Loss: 0.00982617\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 24, Step: 2400, Loss: 0.0168627\n",
      "Epoch: 24, Step: 2410, Loss: 0.0470931\n",
      "Epoch: 24, Step: 2420, Loss: 0.0184158\n",
      "Epoch: 24, Step: 2430, Loss: 0.0110931\n",
      "Epoch: 24, Step: 2440, Loss: 0.118656\n",
      "Epoch: 24, Step: 2450, Loss: 0.407826\n",
      "Epoch: 24, Step: 2460, Loss: 0.189998\n",
      "Epoch: 24, Step: 2470, Loss: 0.0364692\n",
      "Epoch: 24, Step: 2480, Loss: 0.00773005\n",
      "Epoch: 24, Step: 2490, Loss: 0.00760139\n",
      "Epoch: 24, Step: 2500, Loss: 0.00747377\n",
      "Epoch: 24, Step: 2510, Loss: 0.00744423\n",
      "Epoch: 24, Step: 2520, Loss: 0.205818\n",
      "Epoch: 24, Step: 2530, Loss: 5.21873\n",
      "Epoch: 24, Step: 2540, Loss: 0.0955356\n",
      "Epoch: 24, Step: 2550, Loss: 0.0102087\n",
      "Epoch: 24, Step: 2560, Loss: 0.00479016\n",
      "Epoch: 24, Step: 2570, Loss: 0.0116551\n",
      "Epoch: 24, Step: 2580, Loss: 0.0100766\n",
      "Epoch: 24, Step: 2590, Loss: 0.00696361\n",
      "Epoch: 24, Step: 2600, Loss: 0.00254179\n",
      "Epoch: 24, Step: 2610, Loss: 0.00228839\n",
      "Epoch: 24, Step: 2620, Loss: 0.00183489\n",
      "Epoch: 24, Step: 2630, Loss: 0.00204053\n",
      "Epoch: 24, Step: 2640, Loss: 0.00358854\n",
      "Epoch: 24, Step: 2650, Loss: 0.0297634\n",
      "Epoch: 24, Step: 2660, Loss: 0.0457658\n",
      "Epoch: 24, Step: 2670, Loss: 0.02212\n",
      "Epoch: 24, Step: 2680, Loss: 0.000573426\n",
      "Epoch: 24, Step: 2690, Loss: 0.0012962\n",
      "Epoch: 24, Step: 2700, Loss: 0.000539195\n",
      "Epoch: 24, Step: 2710, Loss: 0.00130245\n",
      "Epoch: 24, Step: 2720, Loss: 0.000479156\n",
      "Epoch: 24, Step: 2730, Loss: 0.00119262\n",
      "Epoch: 24, Step: 2740, Loss: 0.000571503\n",
      "Epoch: 24, Step: 2750, Loss: 0.00102825\n",
      "Epoch: 24, Step: 2760, Loss: 0.000651888\n",
      "Epoch: 24, Step: 2770, Loss: 0.00108752\n",
      "Epoch: 24, Step: 2780, Loss: 0.00111474\n",
      "Epoch: 24, Step: 2790, Loss: 0.00136623\n",
      "Epoch: 24, Step: 2800, Loss: 0.000816656\n",
      "Epoch: 24, Step: 2810, Loss: 0.00205352\n",
      "Epoch: 24, Step: 2820, Loss: 0.00844178\n",
      "Epoch: 24, Step: 2830, Loss: 0.0611268\n",
      "Epoch: 24, Step: 2840, Loss: 2.11471\n",
      "Epoch: 24, Step: 2850, Loss: 3.45252\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 25, Step: 2500, Loss: 0.00877791\n",
      "Epoch: 25, Step: 2510, Loss: 0.00313878\n",
      "Epoch: 25, Step: 2520, Loss: 0.0470955\n",
      "Epoch: 25, Step: 2530, Loss: 0.0587482\n",
      "Epoch: 25, Step: 2540, Loss: 0.0551556\n",
      "Epoch: 25, Step: 2550, Loss: 0.0405049\n",
      "Epoch: 25, Step: 2560, Loss: 0.13155\n",
      "Epoch: 25, Step: 2570, Loss: 0.00646867\n",
      "Epoch: 25, Step: 2580, Loss: 0.0202946\n",
      "Epoch: 25, Step: 2590, Loss: 0.0298988\n",
      "Epoch: 25, Step: 2600, Loss: 0.0151377\n",
      "Epoch: 25, Step: 2610, Loss: 0.0119717\n",
      "Epoch: 25, Step: 2620, Loss: 0.0837386\n",
      "Epoch: 25, Step: 2630, Loss: 0.108548\n",
      "Epoch: 25, Step: 2640, Loss: 0.078076\n",
      "Epoch: 25, Step: 2650, Loss: 0.127368\n",
      "Epoch: 25, Step: 2660, Loss: 0.0173459\n",
      "Epoch: 25, Step: 2670, Loss: 0.0373509\n",
      "Epoch: 25, Step: 2680, Loss: 0.0257213\n",
      "Epoch: 25, Step: 2690, Loss: 0.0227868\n",
      "Epoch: 25, Step: 2700, Loss: 0.0221739\n",
      "Epoch: 25, Step: 2710, Loss: 0.0223679\n",
      "Epoch: 25, Step: 2720, Loss: 0.0223649\n",
      "Epoch: 25, Step: 2730, Loss: 0.0229124\n",
      "Epoch: 25, Step: 2740, Loss: 0.0385144\n",
      "Epoch: 25, Step: 2750, Loss: 0.0307548\n",
      "Epoch: 25, Step: 2760, Loss: 0.0337268\n",
      "Epoch: 25, Step: 2770, Loss: 0.00357558\n",
      "Epoch: 25, Step: 2780, Loss: 0.0436249\n",
      "Epoch: 25, Step: 2790, Loss: 0.0914278\n",
      "Epoch: 25, Step: 2800, Loss: 0.018801\n",
      "Epoch: 25, Step: 2810, Loss: 0.538186\n",
      "Epoch: 25, Step: 2820, Loss: 0.536786\n",
      "Epoch: 25, Step: 2830, Loss: 0.14866\n",
      "Epoch: 25, Step: 2840, Loss: 0.0337488\n",
      "Epoch: 25, Step: 2850, Loss: 0.021413\n",
      "Epoch: 25, Step: 2860, Loss: 0.0414523\n",
      "Epoch: 25, Step: 2870, Loss: 0.29358\n",
      "Epoch: 25, Step: 2880, Loss: 1.44691\n",
      "Epoch: 25, Step: 2890, Loss: 0.898867\n",
      "Epoch: 25, Step: 2900, Loss: 0.0659236\n",
      "Epoch: 25, Step: 2910, Loss: 0.0541831\n",
      "Epoch: 25, Step: 2920, Loss: 0.00436371\n",
      "Epoch: 25, Step: 2930, Loss: 0.00390951\n",
      "Epoch: 25, Step: 2940, Loss: 0.00949332\n",
      "Epoch: 25, Step: 2950, Loss: 0.0259261\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 26, Step: 2600, Loss: 0.0606321\n",
      "Epoch: 26, Step: 2610, Loss: 0.00214964\n",
      "Epoch: 26, Step: 2620, Loss: 0.0365343\n",
      "Epoch: 26, Step: 2630, Loss: 0.138825\n",
      "Epoch: 26, Step: 2640, Loss: 0.383645\n",
      "Epoch: 26, Step: 2650, Loss: 0.228269\n",
      "Epoch: 26, Step: 2660, Loss: 0.0186269\n",
      "Epoch: 26, Step: 2670, Loss: 0.0132926\n",
      "Epoch: 26, Step: 2680, Loss: 0.0146334\n",
      "Epoch: 26, Step: 2690, Loss: 0.015624\n",
      "Epoch: 26, Step: 2700, Loss: 0.0173218\n",
      "Epoch: 26, Step: 2710, Loss: 0.887225\n",
      "Epoch: 26, Step: 2720, Loss: 4.4835\n",
      "Epoch: 26, Step: 2730, Loss: 0.0236076\n",
      "Epoch: 26, Step: 2740, Loss: 0.00899905\n",
      "Epoch: 26, Step: 2750, Loss: 0.00945246\n",
      "Epoch: 26, Step: 2760, Loss: 0.0163874\n",
      "Epoch: 26, Step: 2770, Loss: 0.00868448\n",
      "Epoch: 26, Step: 2780, Loss: 0.00769039\n",
      "Epoch: 26, Step: 2790, Loss: 0.00164715\n",
      "Epoch: 26, Step: 2800, Loss: 0.00236354\n",
      "Epoch: 26, Step: 2810, Loss: 0.00328006\n",
      "Epoch: 26, Step: 2820, Loss: 0.0014817\n",
      "Epoch: 26, Step: 2830, Loss: 0.00561532\n",
      "Epoch: 26, Step: 2840, Loss: 0.0300217\n",
      "Epoch: 26, Step: 2850, Loss: 0.0337358\n",
      "Epoch: 26, Step: 2860, Loss: 0.0112034\n",
      "Epoch: 26, Step: 2870, Loss: 0.00210874\n",
      "Epoch: 26, Step: 2880, Loss: 0.00201947\n",
      "Epoch: 26, Step: 2890, Loss: 0.00237515\n",
      "Epoch: 26, Step: 2900, Loss: 0.00158802\n",
      "Epoch: 26, Step: 2910, Loss: 0.00170484\n",
      "Epoch: 26, Step: 2920, Loss: 0.00178087\n",
      "Epoch: 26, Step: 2930, Loss: 0.000869654\n",
      "Epoch: 26, Step: 2940, Loss: 0.00209526\n",
      "Epoch: 26, Step: 2950, Loss: 0.00106641\n",
      "Epoch: 26, Step: 2960, Loss: 0.00115302\n",
      "Epoch: 26, Step: 2970, Loss: 0.00117998\n",
      "Epoch: 26, Step: 2980, Loss: 0.000888185\n",
      "Epoch: 26, Step: 2990, Loss: 0.000540832\n",
      "Epoch: 26, Step: 3000, Loss: 0.000960499\n",
      "Epoch: 26, Step: 3010, Loss: 0.0160574\n",
      "Epoch: 26, Step: 3020, Loss: 0.0517462\n",
      "Epoch: 26, Step: 3030, Loss: 3.11392\n",
      "Epoch: 26, Step: 3040, Loss: 2.31254\n",
      "Epoch: 26, Step: 3050, Loss: 0.00197924\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 27, Step: 2700, Loss: 0.00309975\n",
      "Epoch: 27, Step: 2710, Loss: 0.0721535\n",
      "Epoch: 27, Step: 2720, Loss: 0.0807548\n",
      "Epoch: 27, Step: 2730, Loss: 0.0452026\n",
      "Epoch: 27, Step: 2740, Loss: 0.0558727\n",
      "Epoch: 27, Step: 2750, Loss: 0.0939171\n",
      "Epoch: 27, Step: 2760, Loss: 0.0041026\n",
      "Epoch: 27, Step: 2770, Loss: 0.0295705\n",
      "Epoch: 27, Step: 2780, Loss: 0.0203457\n",
      "Epoch: 27, Step: 2790, Loss: 0.0164458\n",
      "Epoch: 27, Step: 2800, Loss: 0.00692995\n",
      "Epoch: 27, Step: 2810, Loss: 0.112284\n",
      "Epoch: 27, Step: 2820, Loss: 0.0750638\n",
      "Epoch: 27, Step: 2830, Loss: 0.107354\n",
      "Epoch: 27, Step: 2840, Loss: 0.122854\n",
      "Epoch: 27, Step: 2850, Loss: 0.0183544\n",
      "Epoch: 27, Step: 2860, Loss: 0.0198631\n",
      "Epoch: 27, Step: 2870, Loss: 0.0148793\n",
      "Epoch: 27, Step: 2880, Loss: 0.0128408\n",
      "Epoch: 27, Step: 2890, Loss: 0.012684\n",
      "Epoch: 27, Step: 2900, Loss: 0.0132327\n",
      "Epoch: 27, Step: 2910, Loss: 0.0149285\n",
      "Epoch: 27, Step: 2920, Loss: 0.0148372\n",
      "Epoch: 27, Step: 2930, Loss: 0.0271666\n",
      "Epoch: 27, Step: 2940, Loss: 0.024089\n",
      "Epoch: 27, Step: 2950, Loss: 0.0224822\n",
      "Epoch: 27, Step: 2960, Loss: 0.00828061\n",
      "Epoch: 27, Step: 2970, Loss: 0.0489888\n",
      "Epoch: 27, Step: 2980, Loss: 0.0764738\n",
      "Epoch: 27, Step: 2990, Loss: 0.0902062\n",
      "Epoch: 27, Step: 3000, Loss: 0.602616\n",
      "Epoch: 27, Step: 3010, Loss: 0.473036\n",
      "Epoch: 27, Step: 3020, Loss: 0.134053\n",
      "Epoch: 27, Step: 3030, Loss: 0.0446763\n",
      "Epoch: 27, Step: 3040, Loss: 0.019308\n",
      "Epoch: 27, Step: 3050, Loss: 0.055986\n",
      "Epoch: 27, Step: 3060, Loss: 0.441129\n",
      "Epoch: 27, Step: 3070, Loss: 1.40244\n",
      "Epoch: 27, Step: 3080, Loss: 0.595764\n",
      "Epoch: 27, Step: 3090, Loss: 0.112408\n",
      "Epoch: 27, Step: 3100, Loss: 0.0238595\n",
      "Epoch: 27, Step: 3110, Loss: 0.00562556\n",
      "Epoch: 27, Step: 3120, Loss: 0.000750157\n",
      "Epoch: 27, Step: 3130, Loss: 0.0101285\n",
      "Epoch: 27, Step: 3140, Loss: 0.0272127\n",
      "Epoch: 27, Step: 3150, Loss: 0.0506201\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 28, Step: 2800, Loss: 0.00209318\n",
      "Epoch: 28, Step: 2810, Loss: 0.0755459\n",
      "Epoch: 28, Step: 2820, Loss: 0.154019\n",
      "Epoch: 28, Step: 2830, Loss: 0.340012\n",
      "Epoch: 28, Step: 2840, Loss: 0.208156\n",
      "Epoch: 28, Step: 2850, Loss: 0.0114702\n",
      "Epoch: 28, Step: 2860, Loss: 0.008379\n",
      "Epoch: 28, Step: 2870, Loss: 0.00850422\n",
      "Epoch: 28, Step: 2880, Loss: 0.00766678\n",
      "Epoch: 28, Step: 2890, Loss: 0.0134304\n",
      "Epoch: 28, Step: 2900, Loss: 2.16663\n",
      "Epoch: 28, Step: 2910, Loss: 3.38542\n",
      "Epoch: 28, Step: 2920, Loss: 0.013349\n",
      "Epoch: 28, Step: 2930, Loss: 0.00434902\n",
      "Epoch: 28, Step: 2940, Loss: 0.00416886\n",
      "Epoch: 28, Step: 2950, Loss: 0.011147\n",
      "Epoch: 28, Step: 2960, Loss: 0.00428119\n",
      "Epoch: 28, Step: 2970, Loss: 0.00674591\n",
      "Epoch: 28, Step: 2980, Loss: 0.00185604\n",
      "Epoch: 28, Step: 2990, Loss: 0.00216301\n",
      "Epoch: 28, Step: 3000, Loss: 0.00292067\n",
      "Epoch: 28, Step: 3010, Loss: 0.00070106\n",
      "Epoch: 28, Step: 3020, Loss: 0.00793503\n",
      "Epoch: 28, Step: 3030, Loss: 0.043633\n",
      "Epoch: 28, Step: 3040, Loss: 0.0411009\n",
      "Epoch: 28, Step: 3050, Loss: 0.00431145\n",
      "Epoch: 28, Step: 3060, Loss: 0.000672268\n",
      "Epoch: 28, Step: 3070, Loss: 0.000813104\n",
      "Epoch: 28, Step: 3080, Loss: 0.00139775\n",
      "Epoch: 28, Step: 3090, Loss: 0.000355703\n",
      "Epoch: 28, Step: 3100, Loss: 0.00131452\n",
      "Epoch: 28, Step: 3110, Loss: 0.000670338\n",
      "Epoch: 28, Step: 3120, Loss: 0.00032634\n",
      "Epoch: 28, Step: 3130, Loss: 0.001002\n",
      "Epoch: 28, Step: 3140, Loss: 0.000815082\n",
      "Epoch: 28, Step: 3150, Loss: 0.000732985\n",
      "Epoch: 28, Step: 3160, Loss: 0.000641656\n",
      "Epoch: 28, Step: 3170, Loss: 0.0003755\n",
      "Epoch: 28, Step: 3180, Loss: 0.000798499\n",
      "Epoch: 28, Step: 3190, Loss: 0.00141044\n",
      "Epoch: 28, Step: 3200, Loss: 0.0354431\n",
      "Epoch: 28, Step: 3210, Loss: 0.0328565\n",
      "Epoch: 28, Step: 3220, Loss: 4.41844\n",
      "Epoch: 28, Step: 3230, Loss: 1.13069\n",
      "Epoch: 28, Step: 3240, Loss: 0.00291809\n",
      "Epoch: 28, Step: 3250, Loss: 0.0136078\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n",
      "Epoch: 29, Step: 2900, Loss: 0.0555179\n",
      "Epoch: 29, Step: 2910, Loss: 0.0703771\n",
      "Epoch: 29, Step: 2920, Loss: 0.0139582\n",
      "Epoch: 29, Step: 2930, Loss: 0.088118\n",
      "Epoch: 29, Step: 2940, Loss: 0.0893487\n",
      "Epoch: 29, Step: 2950, Loss: 0.00243345\n",
      "Epoch: 29, Step: 2960, Loss: 0.0482536\n",
      "Epoch: 29, Step: 2970, Loss: 0.0141516\n",
      "Epoch: 29, Step: 2980, Loss: 0.0150439\n",
      "Epoch: 29, Step: 2990, Loss: 0.00461429\n",
      "Epoch: 29, Step: 3000, Loss: 0.146542\n",
      "Epoch: 29, Step: 3010, Loss: 0.0475008\n",
      "Epoch: 29, Step: 3020, Loss: 0.125567\n",
      "Epoch: 29, Step: 3030, Loss: 0.0836219\n",
      "Epoch: 29, Step: 3040, Loss: 0.0318654\n",
      "Epoch: 29, Step: 3050, Loss: 0.0205098\n",
      "Epoch: 29, Step: 3060, Loss: 0.0220513\n",
      "Epoch: 29, Step: 3070, Loss: 0.0215907\n",
      "Epoch: 29, Step: 3080, Loss: 0.0230052\n",
      "Epoch: 29, Step: 3090, Loss: 0.0228943\n",
      "Epoch: 29, Step: 3100, Loss: 0.0217604\n",
      "Epoch: 29, Step: 3110, Loss: 0.0204884\n",
      "Epoch: 29, Step: 3120, Loss: 0.0385706\n",
      "Epoch: 29, Step: 3130, Loss: 0.0347153\n",
      "Epoch: 29, Step: 3140, Loss: 0.0227581\n",
      "Epoch: 29, Step: 3150, Loss: 0.0156198\n",
      "Epoch: 29, Step: 3160, Loss: 0.0770568\n",
      "Epoch: 29, Step: 3170, Loss: 0.0545576\n",
      "Epoch: 29, Step: 3180, Loss: 0.23482\n",
      "Epoch: 29, Step: 3190, Loss: 0.604177\n",
      "Epoch: 29, Step: 3200, Loss: 0.346139\n",
      "Epoch: 29, Step: 3210, Loss: 0.108036\n",
      "Epoch: 29, Step: 3220, Loss: 0.0439373\n",
      "Epoch: 29, Step: 3230, Loss: 0.0120587\n",
      "Epoch: 29, Step: 3240, Loss: 0.0958693\n",
      "Epoch: 29, Step: 3250, Loss: 0.702796\n",
      "Epoch: 29, Step: 3260, Loss: 1.51083\n",
      "Epoch: 29, Step: 3270, Loss: 0.37951\n",
      "Epoch: 29, Step: 3280, Loss: 0.107566\n",
      "Epoch: 29, Step: 3290, Loss: 0.00458768\n",
      "Epoch: 29, Step: 3300, Loss: 0.00731872\n",
      "Epoch: 29, Step: 3310, Loss: 0.00346607\n",
      "Epoch: 29, Step: 3320, Loss: 0.012325\n",
      "Epoch: 29, Step: 3330, Loss: 0.0400351\n",
      "Epoch: 29, Step: 3340, Loss: 0.0484998\n",
      "Epoch: 29, Step: 3350, Loss: 0.00542861\n",
      "Model saved in file: model_linear_adam/model_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "LOGDIR = 'model_linear_adam'\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "L2NormConst = 0.001\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(y_, y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op =  tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = 'Driving Data/Autopilot-TensorFlow-master/Autopilot-TensorFlow-master/logs'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "  for i in range(int(num_images/batch_size)):\n",
    "    xs, ys = LoadTrainBatch(batch_size)\n",
    "    train_step.run(feed_dict={x: xs, y_: ys, keep_prob: 0.5})\n",
    "    if i % 10 == 0:\n",
    "      xs, ys = LoadValBatch(batch_size)\n",
    "      loss_value = loss.eval(feed_dict={x:xs, y_: ys, keep_prob: 1.0})\n",
    "      print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "    # write logs at every iteration\n",
    "    summary = merged_summary_op.eval(feed_dict={x:xs, y_: ys, keep_prob: 1.0})\n",
    "    summary_writer.add_summary(summary, epoch * num_images/batch_size + i)\n",
    "\n",
    "    if i % batch_size == 0:\n",
    "      if not os.path.exists(LOGDIR):\n",
    "        os.makedirs(LOGDIR)\n",
    "      checkpoint_path = os.path.join(LOGDIR, \"model_2.ckpt\")\n",
    "      filename = saver.save(sess, checkpoint_path)\n",
    "  print(\"Model saved in file: %s\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZh5eWgucP7X"
   },
   "outputs": [],
   "source": [
    "# Predicting Degrees\n",
    "\n",
    "# i = math.ceil(num_images*0.8)\n",
    "# print(\"Starting frameofvideo:\" +str(i))\n",
    "\n",
    "degrees_predicted = []\n",
    "for i in range(len(val_xs)):\n",
    "    full_image = scipy.misc.imread(val_xs[i], mode=\"RGB\")\n",
    "    image = scipy.misc.imresize(full_image[-150:], [66, 200]) / 255.0\n",
    "    degrees = sess.run(y,feed_dict={x: [image], keep_prob: 1.0})[0][0] * 180.0 / scipy.pi\n",
    "    #call(\"clear\")\n",
    "    #print(\"Predicted Steering angle: \" + str(degrees))\n",
    "    #print(\"Steering angle: \" + str(degrees) + \" (pred)\\t\" + str(val_ys[i]*180/scipy.pi) + \" (actual)\")\n",
    "    #cv2.imshow(\"frame\", cv2.cvtColor(full_image, cv2.COLOR_RGB2BGR))\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    #smoothed_angle += 0.2 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    #M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    #dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    #cv2.imshow(\"steering wheel\", dst)\n",
    "    #i += 1\n",
    "    degrees_predicted.append(degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BTX6I60BdYfQ",
    "outputId": "0808aa8b-c166-4628-d0b1-f78e3b09d212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9081"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PunkYbPpipkP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCez3akDfjZ-"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"degrees\":degrees_predicted,\"original\":[val_ys[i]*180/scipy.pi for i in range(len(val_ys))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "5Wlgz0WahRNk",
    "outputId": "a5c3b313-224e-470d-d91a-e993438cf533"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degrees</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.775987</td>\n",
       "      <td>-10.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.775987</td>\n",
       "      <td>-10.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.775987</td>\n",
       "      <td>-9.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.775987</td>\n",
       "      <td>-7.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.775987</td>\n",
       "      <td>-5.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    degrees  original\n",
       "0  1.775987    -10.79\n",
       "1  1.775987    -10.08\n",
       "2  1.775987     -9.38\n",
       "3  1.775987     -7.56\n",
       "4  1.775987     -5.95"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfX2BRTfxGD1"
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"results_adam_linear.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oGKd2C2QyeTS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Self_driving_car Adam_Linear.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
